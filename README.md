# PhÃ¢n tÃ­ch vÃ  Dá»± Ä‘oÃ¡n GiÃ¡ Tiá»n MÃ£ HÃ³a sá»­ dá»¥ng Apache Spark

**Äá» tÃ i:** PhÃ¢n tÃ­ch vÃ  dá»± Ä‘oÃ¡n xu hÆ°á»›ng giÃ¡ tiá»n mÃ£ hÃ³a (BTC vÃ  ETH) vá»›i Lambda Architecture  
**Sinh viÃªn:** ÄoÃ n Tháº¿ TÃ­n  
**MSSV:** 4551190056  
**Lá»›p:** KTPM45

---

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n xÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n tÃ­ch dá»¯ liá»‡u lá»›n vÃ  dá»± Ä‘oÃ¡n giÃ¡ tiá»n mÃ£ hÃ³a (Bitcoin, Ethereum) sá»­ dá»¥ng **Lambda Architecture** vá»›i Apache Spark, Kafka, vÃ  Facebook Prophet.

### Äáº·c Ä‘iá»ƒm ná»•i báº­t:
- âœ… **Quy mÃ´ dá»¯ liá»‡u:** 50+ triá»‡u dÃ²ng (tick-level 1 phÃºt, 2012-2025)
- âœ… **Lambda Architecture:** Batch Layer + Speed Layer + Serving Layer
- âœ… **Real-time Streaming:** Kafka + Spark Structured Streaming + WebSocket
- âœ… **Machine Learning:** Facebook Prophet vá»›i MAPE < 4%
- âœ… **Dá»¯ liá»‡u sáº¡ch:** 8,140 ngÃ y sau xá»­ lÃ½, backfill gaps tá»± Ä‘á»™ng

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng (Lambda Architecture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                              â”‚
â”‚  - Historical CSV (50M+ rows)                                    â”‚
â”‚  - Binance WebSocket API (Real-time)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BATCH LAYER     â”‚                   â”‚    SPEED LAYER        â”‚
â”‚                   â”‚                   â”‚                       â”‚
â”‚ â€¢ Preprocessing   â”‚                   â”‚ â€¢ WebSocket Producer  â”‚
â”‚ â€¢ Backfill Gaps   â”‚                   â”‚ â€¢ Kafka (1 partition) â”‚
â”‚ â€¢ Daily Aggregate â”‚                   â”‚ â€¢ Spark Streaming     â”‚
â”‚ â€¢ Output: 8,140   â”‚                   â”‚ â€¢ Daily Aggregate     â”‚
â”‚   rows Parquet    â”‚                   â”‚ â€¢ Output: Parquet     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   SERVING LAYER       â”‚
                  â”‚                       â”‚
                  â”‚ â€¢ Merge Batch + Speed â”‚
                  â”‚ â€¢ Deduplication       â”‚
                  â”‚ â€¢ Prophet Input       â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   MACHINE LEARNING    â”‚
                  â”‚                       â”‚
                  â”‚ â€¢ Facebook Prophet    â”‚
                  â”‚ â€¢ MAPE: BTC 3.36%     â”‚
                  â”‚        ETH 3.90%      â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
BigDataProject/
â”‚
â”œâ”€â”€ data/                          # Dá»¯ liá»‡u thÃ´
â”‚   â”œâ”€â”€ btc/BTCUSDT_1min_2012-2025.csv  (28M rows)
â”‚   â””â”€â”€ eth/ETHUSDT_1min_2017-2025.csv  (24M rows)
â”‚
â”œâ”€â”€ data_parquet/                  # Dá»¯ liá»‡u Parquet (partitioned by year)
â”‚   â”œâ”€â”€ btc_clean/                 # BTC Ä‘Ã£ lÃ m sáº¡ch
â”‚   â””â”€â”€ eth_clean/                 # ETH Ä‘Ã£ lÃ m sáº¡ch
â”‚
â”œâ”€â”€ data_analysis/                 # Output phÃ¢n tÃ­ch
â”‚   â”œâ”€â”€ daily_filled/              # Batch Layer output (8,140 rows)
â”‚   â”œâ”€â”€ prophet_input/             # Input cho Prophet (merged)
â”‚   â”œâ”€â”€ prophet_forecasts/         # Káº¿t quáº£ dá»± Ä‘oÃ¡n (Parquet)
â”‚   â”œâ”€â”€ prophet_results/           # Actual vs Predicted (CSV)
â”‚   â”œâ”€â”€ prophet_metrics/           # MAPE, MAE, RMSE
â”‚   â””â”€â”€ prophet_visualizations/    # Biá»ƒu Ä‘á»“ HTML tÆ°Æ¡ng tÃ¡c
â”‚
â”œâ”€â”€ week6_streaming/               # Speed Layer
â”‚   â”œâ”€â”€ docker-compose.yml         # Kafka + Zookeeper
â”‚   â”œâ”€â”€ websocket_producer.py      # Binance WebSocket â†’ Kafka
â”‚   â”œâ”€â”€ spark_streaming_consumer.py # Kafka â†’ Spark Streaming (production)
â”‚   â”œâ”€â”€ kafka_batch_reader.py      # Kafka â†’ Batch read (demo nhanh)
â”‚   â”œâ”€â”€ checkpoint_spark/          # Checkpoint metadata
â”‚   â””â”€â”€ streaming_output_spark_BATCH/ # Speed Layer output (2 rows)
â”‚
â”œâ”€â”€ scripts/                       # Source code
â”‚   â”œâ”€â”€ preprocessing/             # 4 scripts tiá»n xá»­ lÃ½
â”‚   â”‚   â”œâ”€â”€ convert_to_parquet.py
â”‚   â”‚   â”œâ”€â”€ clean_parquet.py
â”‚   â”‚   â”œâ”€â”€ preprocess_step1.py
â”‚   â”‚   â””â”€â”€ preprocess_step2.py
â”‚   â”‚
â”‚   â”œâ”€â”€ lambda_batch/              # Batch Layer
â”‚   â”‚   â”œâ”€â”€ week6_backfill.py      # Backfill gaps < 30 ngÃ y
â”‚   â”‚   â”œâ”€â”€ week6_backfill_batch.py # Backfill gaps lá»›n
â”‚   â”‚   â””â”€â”€ week6_merge.py         # Merge Batch + Speed
â”‚   â”‚
â”‚   â””â”€â”€ ml_models/                 # Machine Learning
â”‚       â””â”€â”€ prophet_train.py       # Train & forecast Prophet
â”‚
â”œâ”€â”€ docs/                          # TÃ i liá»‡u (sáº½ táº¡o láº¡i)
â””â”€â”€ README.md                      # File nÃ y
```

---

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y

### **1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng**

```bash
# CÃ i Ä‘áº·t dependencies
pip install pyspark pandas numpy matplotlib prophet requests websocket-client

# CÃ i Docker Desktop (cho Kafka)
# Download: https://www.docker.com/products/docker-desktop
```

### **2. Preprocessing (Batch Layer - BÆ°á»›c 1)**

```bash
# BÆ°á»›c 1: Chuyá»ƒn CSV â†’ Parquet
cd D:\BigDataProject
python scripts/preprocessing/convert_to_parquet.py

# BÆ°á»›c 2: LÃ m sáº¡ch dá»¯ liá»‡u
python scripts/preprocessing/clean_parquet.py

# BÆ°á»›c 3: Táº¡o daily aggregates
python scripts/preprocessing/preprocess_step1.py

# BÆ°á»›c 4: Äiá»n gaps vÃ  tÃ­nh MA
python scripts/preprocessing/preprocess_step2.py
```

**Output:** `data_analysis/daily_filled/` (~7,980 rows)

### **3. Backfill Gaps (Batch Layer - BÆ°á»›c 2)**

```bash
# Backfill gaps nhá» (<30 ngÃ y)
python scripts/lambda_batch/week6_backfill.py

# Backfill gap lá»›n (79 ngÃ y, Nov-Dec 2024)
python scripts/lambda_batch/week6_backfill_batch.py
```

**Output:** `data_analysis/daily_filled/` (8,140 rows - HOÃ€N CHá»ˆNH)

### **4. Speed Layer (Real-time Streaming)**

```bash
# BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Kafka
cd week6_streaming
docker-compose up -d

# Äá»£i 15s Ä‘á»ƒ Kafka khá»Ÿi Ä‘á»™ng
# Verify: docker ps (2 containers running)

# BÆ°á»›c 2: Táº¡o topic (1 partition)
docker exec kafka kafka-topics --create --topic crypto-prices \
  --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092

# BÆ°á»›c 3: Cháº¡y Producer (Terminal 1)
python websocket_producer.py
# Gá»­i real-time data tá»« Binance â†’ Kafka

# BÆ°á»›c 4: Cháº¡y Consumer (Terminal 2)
python spark_streaming_consumer.py
# Äá»c tá»« Kafka â†’ Aggregate â†’ Parquet

# Hoáº·c cháº¡y batch reader (demo nhanh):
python kafka_batch_reader.py
```

**Output:** `streaming_output_spark_BATCH/` (2 rows: BTCUSDT, ETHUSDT ngÃ y 2025-12-14)

### **5. Serving Layer (Merge Batch + Speed)**

```bash
# Merge dá»¯ liá»‡u tá»« Batch + Speed Layer
python scripts/lambda_batch/week6_merge.py
```

**Output:** 
- `data_analysis/daily_filled/` (8,140 rows - overwrite with cache)
- `data_analysis/prophet_input/` (8,140 rows - ready for ML)

### **6. Machine Learning (Prophet)**

```bash
# Train vÃ  forecast
python scripts/ml_models/prophet_train.py
```

**Output:**
- `prophet_forecasts/` - Dá»± Ä‘oÃ¡n 30 ngÃ y (Parquet)
- `prophet_metrics/metrics.csv` - MAPE, MAE, RMSE
- `prophet_results/` - Actual vs Predicted CSV
- `prophet_visualizations/` - Biá»ƒu Ä‘á»“ HTML tÆ°Æ¡ng tÃ¡c

**Backup tá»± Ä‘á»™ng:**
- Má»—i láº§n cháº¡y láº¡i â†’ backup sang `*_backup/`
- Äáº£m báº£o khÃ´ng máº¥t káº¿t quáº£ cÅ©

---

## ğŸ“Š Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c

### **1. Batch Layer**
- âœ… **Dá»¯ liá»‡u gá»‘c:** 50M+ rows (CSV 1-phÃºt)
- âœ… **Sau preprocessing:** 7,980 rows daily
- âœ… **Sau backfill:** 8,140 rows (100% complete tá»« 2017-2025)
- âœ… **Features:** OHLCV + MA7 + MA30

### **2. Speed Layer**
- âœ… **Kafka:** 1 partition, 1,008 messages
- âœ… **WebSocket Producer:** Binance real-time API
- âœ… **Spark Streaming Consumer:** Micro-batch 10s
- âœ… **Output:** 2 rows daily aggregate (BTCUSDT, ETHUSDT)

### **3. Serving Layer**
- âœ… **Merge:** Batch (8,140) + Speed (2) = 8,140 rows
- âœ… **Deduplication:** Batch priority, bá» Speed trÃ¹ng ngÃ y
- âœ… **Cache fix:** TrÃ¡nh conflict khi ghi Parquet
- âœ… **Prophet input:** OHLCV + MA7 + MA30

### **4. Machine Learning**
| Coin | MAPE | MAE | RMSE |
|------|------|-----|------|
| **BTCUSDT** | **3.36%** | $2,994 | $3,682 |
| **ETHUSDT** | **3.90%** | $120.43 | $145.82 |

**Káº¿t luáº­n:** MAPE < 4% â†’ MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n ráº¥t tá»‘t!

---

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

### **Big Data**
- **Apache Spark 3.5.3:** PySpark, SparkSQL, Structured Streaming
- **Apache Kafka:** Message broker (Confluent 7.5.0)
- **Parquet:** Columnar storage format
- **Docker:** Container cho Kafka + Zookeeper

### **Machine Learning**
- **Facebook Prophet:** Time series forecasting
- **Pandas:** Data manipulation
- **NumPy:** Numerical computation

### **Visualization**
- **Matplotlib:** Static plots
- **Plotly:** Interactive HTML charts

### **Real-time Data**
- **WebSocket:** Binance Ticker API
- **Requests:** HTTP API calls

---

## ğŸ“ˆ Demo Workflow

### **Scenario: Dá»± Ä‘oÃ¡n giÃ¡ BTC hÃ´m nay**

```bash
# 1. Láº¥y data real-time (Speed Layer)
python week6_streaming/websocket_producer.py  # Cháº¡y 5 phÃºt
python week6_streaming/kafka_batch_reader.py   # Aggregate

# 2. Merge vá»›i Batch Layer
python scripts/lambda_batch/week6_merge.py

# 3. Forecast vá»›i Prophet
python scripts/ml_models/prophet_train.py

# 4. Xem káº¿t quáº£
# Má»Ÿ: data_analysis/prophet_visualizations/BTCUSDT_forecast_interactive.html
```

**Káº¿t quáº£:** Biá»ƒu Ä‘á»“ dá»± Ä‘oÃ¡n giÃ¡ BTC 30 ngÃ y tá»›i vá»›i confidence interval!

---

## ğŸ¯ So sÃ¡nh vá»›i Äá» cÆ°Æ¡ng

| YÃªu cáº§u | Äá» cÆ°Æ¡ng gá»‘c | Thá»±c hiá»‡n |
|---------|--------------|-----------|
| **Quy mÃ´ dá»¯ liá»‡u** | 50-100M rows | âœ… 50M+ rows |
| **Streaming** | Poll API Ä‘Æ¡n giáº£n | âœ… **Kafka + WebSocket** ğŸŒŸ |
| **Architecture** | KhÃ´ng rÃµ | âœ… **Lambda Architecture** ğŸŒŸ |
| **ML Model** | Prophet | âœ… Prophet MAPE < 4% |
| **Visualization** | Matplotlib | âœ… Matplotlib + Plotly HTML |

**Äiá»ƒm cá»™ng lá»›n:**
- ğŸŒŸ **Kafka + Docker:** Production-ready streaming
- ğŸŒŸ **Lambda Architecture:** Batch + Speed + Serving
- ğŸŒŸ **MAPE < 4%:** Dá»± Ä‘oÃ¡n ráº¥t chÃ­nh xÃ¡c

---

## ğŸ“ TÃ i liá»‡u tham kháº£o

1. Apache Spark Documentation: https://spark.apache.org/docs/latest/
2. Facebook Prophet: https://facebook.github.io/prophet/
3. Confluent Kafka: https://docs.confluent.io/
4. Binance WebSocket API: https://binance-docs.github.io/apidocs/spot/en/
5. Lambda Architecture: http://lambda-architecture.net/

---

## ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

**ÄoÃ n Tháº¿ TÃ­n**  
MSSV: 4551190056  
Lá»›p: KTPM45  
Email: [ThÃªm email náº¿u cáº§n]

---

## ğŸ“… Timeline thá»±c hiá»‡n

- **Tuáº§n 1-2:** Thu tháº­p vÃ  preprocessing dá»¯ liá»‡u (50M rows)
- **Tuáº§n 3:** Batch Layer (daily aggregates, backfill)
- **Tuáº§n 4:** Machine Learning (Prophet training, MAPE < 4%)
- **Tuáº§n 5:** Tá»• chá»©c code, documentation
- **Tuáº§n 6:** Speed Layer (Kafka + Spark Streaming) â­
- **Tuáº§n 7-8:** HoÃ n thiá»‡n bÃ¡o cÃ¡o vÃ  demo

---

## ğŸ“ Ghi chÃº

Dá»± Ã¡n nÃ y lÃ  Ä‘á»“ Ã¡n cÃ¡ nhÃ¢n mÃ´n Big Data Analytics, minh há»a quy trÃ¬nh phÃ¢n tÃ­ch dá»¯ liá»‡u lá»›n tá»« thu tháº­p, xá»­ lÃ½, Ä‘áº¿n dá»± Ä‘oÃ¡n vá»›i cÃ´ng nghá»‡ production-ready (Kafka, Spark Streaming, Lambda Architecture).

**License:** Educational use only.

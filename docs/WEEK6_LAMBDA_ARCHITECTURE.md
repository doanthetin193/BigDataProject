# WEEK 6 - LAMBDA ARCHITECTURE

## ğŸ—ï¸ KIáº¾N TRÃšC Tá»”NG QUAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAMBDA ARCHITECTURE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ“¦ BATCH LAYER (Historical Processing)                            â”‚
â”‚  â”œâ”€ Input: Binance API historical data                            â”‚
â”‚  â”œâ”€ Processing: Clean â†’ Daily OHLC â†’ Forward Fill â†’ MA7/MA30      â”‚
â”‚  â”œâ”€ Output: data_analysis/daily_filled/                           â”‚
â”‚  â””â”€ Run: python week6_backfill.py (when needed)                   â”‚
â”‚                                                                     â”‚
â”‚  âš¡ SPEED LAYER (Real-time Processing)                             â”‚
â”‚  â”œâ”€ Input: Binance API live stream                                â”‚
â”‚  â”œâ”€ Processing: Kafka â†’ Spark Streaming â†’ Windowing               â”‚
â”‚  â”œâ”€ Output: streaming_output_spark/daily/                         â”‚
â”‚  â””â”€ Run: Streaming (continuous when machine is on)                â”‚
â”‚                                                                     â”‚
â”‚  ğŸ¯ SERVING LAYER (Unified View)                                   â”‚
â”‚  â”œâ”€ Input: Batch + Speed Layer data                               â”‚
â”‚  â”œâ”€ Processing: Merge â†’ Dedup â†’ Recompute MA7/MA30                â”‚
â”‚  â”œâ”€ Output: Unified daily_filled + prophet_input                  â”‚
â”‚  â””â”€ Run: python week6_merge.py (after collecting streaming data)  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ QUY TRÃŒNH Sá»¬ Dá»¤NG

### **BÆ¯á»šC 1: Backfill Historical Gap (Cháº¡y 1 láº§n Ä‘áº§u)**

```bash
python week6_backfill.py
```

**Chá»©c nÄƒng:**
- PhÃ¡t hiá»‡n ngÃ y cuá»‘i cÃ¹ng trong data (tá»« Week 1-5)
- Fetch dá»¯ liá»‡u tá»« ngÃ y Ä‘Ã³ â†’ hÃ´m nay (Binance API)
- Xá»­ lÃ½: Clean, daily OHLC, forward fill, MA7/MA30
- LÆ°u vÃ o `data_analysis/daily_filled/`

**Káº¿t quáº£:**
```
Last date: 2025-09-25
Today: 2025-11-24
Gap: 60 days

Fetching BTCUSDT... âœ… 84,961 rows
Fetching ETHUSDT... âœ… 84,961 rows

Daily aggregation: 120 rows
Forward fill: 120 rows
MA7/MA30 computed

âœ… Saved to data_analysis/daily_filled/
```

---

### **BÆ¯á»šC 2: Start Streaming (Cháº¡y liÃªn tá»¥c khi cÃ³ thá»ƒ)**

**Terminal 1 - Start Kafka + Zookeeper:**
```bash
cd week6_streaming
docker-compose up -d
```

**Terminal 2 - Start Producer:**
```bash
python week6_streaming/websocket_producer.py
```
â†’ Poll Binance API má»—i 1 giÃ¢y, gá»­i vÃ o Kafka

**Terminal 3 - Start Consumer:**
```bash
python week6_streaming/spark_streaming_consumer.py
```
â†’ Spark Structured Streaming xá»­ lÃ½ real-time

**Káº¿t quáº£:**
- Streaming cháº¡y liÃªn tá»¥c
- Thu tháº­p dá»¯ liá»‡u real-time vÃ o `streaming_output_spark/daily/`
- Watermarking, windowing, checkpointing tá»± Ä‘á»™ng

---

### **BÆ¯á»šC 3: Merge Batch + Streaming (Khi cáº§n timeline hoÃ n chá»‰nh)**

```bash
python week6_merge.py
```

**Chá»©c nÄƒng:**
- Äá»c batch data (backfill)
- Äá»c streaming data
- Merge, dedup, recompute MA7/MA30
- Táº¡o timeline liá»n máº¡ch

**Káº¿t quáº£:**
```
Batch data: 120 rows (26/9 - 24/11)
Streaming data: 5 rows (24/11 - 29/11)
Merged: 125 rows

âœ… Unified timeline: 2012 â†’ 29/11/2025
```

---

## ğŸ¯ SCENARIO THá»°C Táº¾ SINH VIÃŠN

### **Scenario 1: Láº§n Ä‘áº§u setup (HÃ´m nay 24/11)**

```bash
# BÆ°á»›c 1: Backfill gap
python week6_backfill.py
# â†’ Láº¥y 26/9 â†’ 24/11 (60 ngÃ y)

# BÆ°á»›c 2: Start streaming
cd week6_streaming
docker-compose up -d
python websocket_producer.py &
python spark_streaming_consumer.py

# Äá»ƒ streaming cháº¡y 2-3 giá», thu tháº­p data
# Sau Ä‘Ã³ táº¯t (Ctrl+C) vÃ  táº¯t mÃ¡y
```

---

### **Scenario 2: VÃ o láº¡i sau vÃ i ngÃ y (28/11)**

```bash
# BÆ°á»›c 1: Backfill gap má»›i
python week6_backfill.py
# â†’ Tá»± Ä‘á»™ng phÃ¡t hiá»‡n thiáº¿u 25/11 - 27/11
# â†’ Fetch 3 ngÃ y tá»« Binance API

# BÆ°á»›c 2: Start streaming láº¡i
cd week6_streaming
docker-compose up -d
python websocket_producer.py &
python spark_streaming_consumer.py

# Cháº¡y thÃªm vÃ i giá», thu tháº­p 28/11
```

---

### **Scenario 3: TrÃ¬nh bÃ y final (15/12)**

```bash
# BÆ°á»›c 1: Backfill láº§n cuá»‘i
python week6_backfill.py
# â†’ Láº¥y 25/11 â†’ 15/12

# BÆ°á»›c 2: Merge táº¥t cáº£ data
python week6_merge.py
# â†’ Táº¡o timeline hoÃ n chá»‰nh 2012 â†’ 15/12

# BÆ°á»›c 3: Train Prophet vá»›i data má»›i
python prophet_train.py

# BÆ°á»›c 4: Demo streaming live cho giáº£ng viÃªn
cd week6_streaming
docker-compose up -d
python websocket_producer.py &
python spark_streaming_consumer.py
# â†’ Cho giáº£ng viÃªn tháº¥y real-time processing
```

---

## ğŸ“Š Cáº¤U TRÃšC OUTPUT

```
data_analysis/
â”œâ”€â”€ daily_filled/              â† Batch Layer output (backfill)
â”‚   â”œâ”€â”€ symbol=BTCUSDT/
â”‚   â””â”€â”€ symbol=ETHUSDT/
â”‚
â”œâ”€â”€ prophet_input/             â† Ready for forecasting
â”‚   â”œâ”€â”€ symbol=BTCUSDT/
â”‚   â””â”€â”€ symbol=ETHUSDT/
â”‚
â””â”€â”€ (after merge complete, daily_filled contains unified data)

streaming_output_spark/
â””â”€â”€ daily/                     â† Speed Layer output (streaming)
    â”œâ”€â”€ symbol=BTCUSDT/
    â””â”€â”€ symbol=ETHUSDT/
```

---

## ğŸ“ TRÃŒNH BÃ€Y CHO GIáº¢NG VIÃŠN

### **1. Giá»›i thiá»‡u Lambda Architecture:**

"Em Ã¡p dá»¥ng Lambda Architecture cho Week 6 vÃ¬:
- âœ… ÄÃºng yÃªu cáº§u Streaming (Speed Layer)
- âœ… Giáº£i quyáº¿t constraint sinh viÃªn (khÃ´ng cÃ³ server 24/7)
- âœ… KhÃ´ng bá» sÃ³t data (Batch Layer backfill)
- âœ… Timeline liá»n máº¡ch (Serving Layer merge)"

---

### **2. Demo Batch Layer:**

```bash
python week6_backfill.py
```

"Script tá»± Ä‘á»™ng:
- PhÃ¡t hiá»‡n gap trong data
- Fetch tá»« Binance API
- Xá»­ lÃ½ giá»‘ng pipeline Week 1-5 (clean, forward fill, MA7/MA30)
- LÆ°u vÃ o daily_filled"

---

### **3. Demo Speed Layer (Streaming):**

```bash
# Terminal 1
cd week6_streaming
docker-compose up -d

# Terminal 2
python websocket_producer.py

# Terminal 3
python spark_streaming_consumer.py
```

"Streaming architecture:
- Kafka: Message broker (buffering, fault tolerance)
- Producer: Poll Binance API má»—i 1 giÃ¢y
- Consumer: Spark Structured Streaming
- Features: Watermarking (1 hour), Windowing (1 day), Checkpointing"

**Cho giáº£ng viÃªn tháº¥y console output:**
```
Batch 0: BTCUSDT $84,569, ETHUSDT $2,757
Batch 1: BTCUSDT $84,601, ETHUSDT $2,763
...
```

---

### **4. Demo Serving Layer:**

```bash
python week6_merge.py
```

"Merge batch + streaming:
- Union 2 data sources
- Remove duplicates
- Recompute MA7/MA30 cho toÃ n bá»™ timeline
- Káº¿t quáº£: Timeline liá»n máº¡ch 2012 â†’ hÃ´m nay"

---

### **5. Káº¿t luáº­n:**

"Lambda Architecture cho phÃ©p em:
- **Batch Layer:** Xá»­ lÃ½ lá»‹ch sá»­ khi táº¯t mÃ¡y (backfill)
- **Speed Layer:** Xá»­ lÃ½ real-time khi mÃ¡y báº­t (streaming)
- **Serving Layer:** Merge táº¡o view thá»‘ng nháº¥t

ÄÃ¢y lÃ  practice chuáº©n trong Big Data production khi cÃ³ constraints vá» infrastructure."

---

## âœ… Æ¯U ÄIá»‚M

| Aspect | Lambda Architecture |
|--------|---------------------|
| **ÄÃºng Ä‘á» cÆ°Æ¡ng** | âœ… CÃ³ Streaming (Speed Layer) |
| **Sinh viÃªn** | âœ… KhÃ´ng cáº§n server 24/7 |
| **Data loss** | âœ… Backfill khi táº¯t mÃ¡y |
| **Timeline** | âœ… Liá»n máº¡ch (batch + streaming) |
| **Complexity** | âš ï¸ Vá»«a pháº£i (3 scripts) |
| **CÆ¡ sá»Ÿ lÃ½ thuyáº¿t** | âœ… Nathan Marz - Big Data standard |

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

- **Lambda Architecture:** Nathan Marz (2011)
- **Spark Structured Streaming:** Apache Spark Documentation
- **Kafka:** Apache Kafka Documentation
- **Binance API:** Binance Official API Docs

---

## ğŸ¯ CHECKLIST TRÆ¯á»šC KHI TRÃŒNH BÃ€Y

- [ ] Run week6_backfill.py thÃ nh cÃ´ng
- [ ] Docker Desktop Ä‘ang cháº¡y
- [ ] Kafka + Zookeeper up (docker-compose up -d)
- [ ] Streaming cháº¡y Ä‘Æ°á»£c Ã­t nháº¥t 1-2 giá» (cÃ³ data)
- [ ] Run week6_merge.py thÃ nh cÃ´ng
- [ ] daily_filled cÃ³ data liá»n máº¡ch
- [ ] Hiá»ƒu rÃµ Lambda Architecture concept
- [ ] Chuáº©n bá»‹ giáº£i thÃ­ch táº¡i sao dÃ¹ng approach nÃ y

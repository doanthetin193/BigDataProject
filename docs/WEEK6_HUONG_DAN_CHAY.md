# üìò H∆Ø·ªöNG D·∫™N CH·∫†Y WEEK 6 - LAMBDA ARCHITECTURE

## üéØ T·ªïng quan

Week 6 s·ª≠ d·ª•ng **Lambda Architecture** g·ªìm 3 layer:
- **Batch Layer**: Backfill d·ªØ li·ªáu gap t·ª´ Binance API
- **Speed Layer**: Streaming real-time qua Kafka + Spark
- **Serving Layer**: Merge batch + streaming ‚Üí Forecast

---

## üìã Y√™u c·∫ßu tr∆∞·ªõc khi ch·∫°y

### 1. Ph·∫ßn m·ªÅm c·∫ßn c√†i ƒë·∫∑t:
- ‚úÖ Python 3.10+
- ‚úÖ Docker Desktop (ƒë√£ c√†i v√† ch·∫°y)
- ‚úÖ C√°c th∆∞ vi·ªán Python: `pyspark`, `kafka-python`, `requests`, `prophet`

### 2. Ki·ªÉm tra Docker:
```powershell
# M·ªü Docker Desktop tr∆∞·ªõc
# Sau ƒë√≥ ki·ªÉm tra:
docker --version
docker ps
```

---

## üöÄ C√ÅC B∆Ø·ªöC CH·∫†Y

### B∆Ø·ªöC 1: Backfill d·ªØ li·ªáu gap (Batch Layer)

**M·ª•c ƒë√≠ch**: T·ª± ƒë·ªông ph√°t hi·ªán v√† fetch d·ªØ li·ªáu t·ª´ ng√†y cu·ªëi c√πng trong database ƒë·∫øn h√¥m nay.

```powershell
cd D:\BigDataProject
python week6_backfill.py
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
[STEP 1] Detecting last date in existing data...
  ‚úÖ Last date found in daily_filled: 2025-XX-XX
  üìÖ Today: 2025-XX-XX
  üìä Gap: X days

  üéØ Will backfill: 2025-XX-XX ‚Üí 2025-XX-XX (X days)

[STEP 2] Fetching data from Binance API...
  ‚úÖ Fetched XXXX rows

...

‚úÖ BACKFILL COMPLETE (BATCH LAYER)
```

**L∆∞u √Ω:**
- C·∫ßn c√≥ k·∫øt n·ªëi Internet ƒë·ªÉ fetch t·ª´ Binance API
- N·∫øu kh√¥ng c√≥ gap (ch·∫°y c√πng ng√†y), script s·∫Ω b√°o "No gap detected"

---

### B∆Ø·ªöC 2: Kh·ªüi ƒë·ªông Kafka (Speed Layer - Ph·∫ßn 1)

**M·ª•c ƒë√≠ch**: Kh·ªüi ƒë·ªông Kafka + Zookeeper ƒë·ªÉ nh·∫≠n d·ªØ li·ªáu streaming.

```powershell
cd D:\BigDataProject\week6_streaming
docker-compose up -d
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
[+] Running 3/3
 ‚úî Network week6_streaming_crypto-network  Created
 ‚úî Container zookeeper                     Started
 ‚úî Container kafka                         Started
```

**Ki·ªÉm tra containers ƒë√£ ch·∫°y:**
```powershell
docker ps
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
CONTAINER ID   IMAGE                             STATUS          PORTS                    NAMES
xxxx           confluentinc/cp-kafka:7.5.0       Up X seconds    0.0.0.0:9092->9092/tcp   kafka
xxxx           confluentinc/cp-zookeeper:7.5.0   Up X seconds    0.0.0.0:2181->2181/tcp   zookeeper
```

**‚ö†Ô∏è N·∫øu Kafka kh√¥ng ch·∫°y (ch·ªâ th·∫•y zookeeper):**
```powershell
# Xem log l·ªói
docker logs kafka

# N·∫øu l·ªói "InconsistentClusterIdException", ch·∫°y:
docker-compose down -v
docker-compose up -d
```

**Ch·ªù 10-15 gi√¢y** ƒë·ªÉ Kafka kh·ªüi ƒë·ªông ho√†n to√†n tr∆∞·ªõc khi ch·∫°y b∆∞·ªõc ti·∫øp theo.

---

### B∆Ø·ªöC 3: Ch·∫°y Producer (Speed Layer - Ph·∫ßn 2)

**M·ª•c ƒë√≠ch**: Fetch d·ªØ li·ªáu real-time t·ª´ Binance API v√† g·ª≠i v√†o Kafka.

**M·ªü Terminal m·ªõi (Terminal 2):**
```powershell
cd D:\BigDataProject
python week6_streaming/websocket_producer.py
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
======================================================================
BINANCE API ‚Üí KAFKA PRODUCER
Continuous Streaming (1 second interval)
======================================================================
‚úì Producer connected
‚úì Sending real-time data to Kafka topic: crypto-prices

Press Ctrl+C to stop

üìä BTCUSDT: $XX,XXX.XX | Vol: XX,XXX | Change: +X.XX% | Messages: XX
üìä ETHUSDT: $X,XXX.XX | Vol: XXX,XXX | Change: +X.XX% | Messages: XX
```

**ƒê·ªÉ ch·∫°y 1-2 ph√∫t** ƒë·ªÉ collect ƒë·ªß d·ªØ li·ªáu demo, sau ƒë√≥ **nh·∫•n Ctrl+C** ƒë·ªÉ d·ª´ng.

**‚ö†Ô∏è N·∫øu l·ªói "NoBrokersAvailable":**
- Kafka ch∆∞a s·∫µn s√†ng, ch·ªù th√™m 10-15 gi√¢y r·ªìi ch·∫°y l·∫°i
- Ho·∫∑c ki·ªÉm tra `docker ps` xem Kafka c√≥ ƒëang ch·∫°y kh√¥ng

---

### B∆Ø·ªöC 4: Ki·ªÉm tra d·ªØ li·ªáu trong Kafka (T√πy ch·ªçn)

**M·ª•c ƒë√≠ch**: X√°c nh·∫≠n d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c g·ª≠i v√†o Kafka.

```powershell
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic crypto-prices --from-beginning --max-messages 3
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```json
{"symbol": "BTCUSDT", "price": 92817.92, "volume": 29318.80, ...}
{"symbol": "ETHUSDT", "price": 3031.0, "volume": 531945.72, ...}
{"symbol": "BTCUSDT", "price": 92820.00, ...}
Processed a total of 3 messages
```

---

### B∆Ø·ªöC 5: Merge d·ªØ li·ªáu (Serving Layer)

**M·ª•c ƒë√≠ch**: K·∫øt h·ª£p d·ªØ li·ªáu Batch + Streaming th√†nh m·ªôt timeline th·ªëng nh·∫•t.

```powershell
cd D:\BigDataProject
python week6_merge.py
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
================================================================================
WEEK 6 - SERVING LAYER (Lambda Architecture)
Merge Batch + Streaming Data
================================================================================

[STEP 1] Reading Batch Layer (backfill data)...
  ‚úÖ Batch data loaded: XX rows

[STEP 2] Reading Speed Layer (streaming data)...
  ‚ö†Ô∏è  No streaming data found (ho·∫∑c ‚úÖ Streaming data loaded: XX rows)

‚úÖ Using batch data only (ho·∫∑c ‚úÖ Merged: XX rows)
```

**L∆∞u √Ω:** N·∫øu streaming ch∆∞a ch·∫°y ƒë·ªß l√¢u (< 1 ng√†y), s·∫Ω kh√¥ng c√≥ output file. Script v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng v·ªõi batch data.

---

### B∆Ø·ªöC 6: Ch·∫°y Prophet Forecast

**M·ª•c ƒë√≠ch**: D·ª± ƒëo√°n gi√° crypto d·ª±a tr√™n d·ªØ li·ªáu ƒë√£ merge.

```powershell
python prophet_train.py
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
‚úÖ Backed up week4_forecasts ‚Üí week4_forecasts_old
‚úÖ Backed up week4_visualizations ‚Üí week4_visualizations_old
...

=== Processing BTCUSDT ===
BTCUSDT - Train: XX rows, Test: XX rows
...
BTCUSDT - MAPE: X.XX%

=== Processing ETHUSDT ===
...

=== Summary ===
  symbol      mse       mape    mode
  BTCUSDT     XXXXX     X.XX    multiplicative
  ETHUSDT     XXXXX     X.XX    additive

‚úÖ Forecast & evaluation complete!
```

---

### B∆Ø·ªöC 7: D·ª´ng Kafka (Cleanup)

**Sau khi demo xong:**
```powershell
cd D:\BigDataProject\week6_streaming
docker-compose down
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
[+] Running 3/3
 ‚úî Container kafka      Removed
 ‚úî Container zookeeper  Removed
 ‚úî Network week6_streaming_crypto-network  Removed
```

---

## üìÅ C·∫§U TR√öC OUTPUT

Sau khi ch·∫°y xong, c√°c output s·∫Ω n·∫±m ·ªü:

```
data_analysis/
‚îú‚îÄ‚îÄ daily_filled/              ‚Üê D·ªØ li·ªáu ƒë√£ backfill (Batch Layer)
‚îú‚îÄ‚îÄ prophet_input/             ‚Üê Input cho Prophet
‚îú‚îÄ‚îÄ week4_forecasts/           ‚Üê Forecast M·ªöI
‚îú‚îÄ‚îÄ week4_forecasts_old/       ‚Üê Forecast C≈® (backup)
‚îú‚îÄ‚îÄ week4_visualizations/      ‚Üê Bi·ªÉu ƒë·ªì M·ªöI
‚îú‚îÄ‚îÄ week4_visualizations_old/  ‚Üê Bi·ªÉu ƒë·ªì C≈® (backup)
‚îú‚îÄ‚îÄ week4_results/             ‚Üê Actual vs Predicted
‚îî‚îÄ‚îÄ week4_metrics/             ‚Üê MAPE metrics
```

---

## üîÑ QUICK START (Ch·∫°y nhanh)

N·∫øu ƒë√£ quen, c√≥ th·ªÉ ch·∫°y tu·∫ßn t·ª±:

```powershell
# Terminal 1:
cd D:\BigDataProject

# B∆∞·ªõc 1: Backfill
python week6_backfill.py

# B∆∞·ªõc 2: Start Kafka
cd week6_streaming
docker-compose up -d
Start-Sleep -Seconds 15

# B∆∞·ªõc 3: Producer (ch·∫°y 1-2 ph√∫t r·ªìi Ctrl+C)
cd ..
python week6_streaming/websocket_producer.py

# B∆∞·ªõc 4: Merge
python week6_merge.py

# B∆∞·ªõc 5: Forecast
python prophet_train.py

# B∆∞·ªõc 6: Cleanup
cd week6_streaming
docker-compose down
```

---

## ‚ùì X·ª¨ L√ù L·ªñI TH∆Ø·ªúNG G·∫∂P

### 1. L·ªói "NoBrokersAvailable"
```
kafka.errors.NoBrokersAvailable: NoBrokersAvailable
```
**Nguy√™n nh√¢n:** Kafka ch∆∞a kh·ªüi ƒë·ªông xong
**Gi·∫£i ph√°p:** Ch·ªù 15-20 gi√¢y r·ªìi ch·∫°y l·∫°i

### 2. L·ªói "InconsistentClusterIdException"
```
The Cluster ID xxx doesn't match stored clusterId
```
**Nguy√™n nh√¢n:** Volume c≈© conflict v·ªõi cluster m·ªõi
**Gi·∫£i ph√°p:**
```powershell
cd week6_streaming
docker-compose down -v    # -v ƒë·ªÉ x√≥a volume
docker-compose up -d
```

### 3. L·ªói "Connection to api.binance.com timed out"
**Nguy√™n nh√¢n:** M·∫°ng ch·∫≠m ho·∫∑c b·ªã ch·∫∑n
**Gi·∫£i ph√°p:** 
- Ki·ªÉm tra k·∫øt n·ªëi Internet
- T·∫Øt VPN n·∫øu c√≥
- Th·ª≠ l·∫°i sau v√†i gi√¢y

### 4. Kafka container kh√¥ng ch·∫°y (ch·ªâ th·∫•y zookeeper)
**Gi·∫£i ph√°p:**
```powershell
docker logs kafka          # Xem l·ªói
docker-compose down -v     # Reset
docker-compose up -d       # Kh·ªüi ƒë·ªông l·∫°i
```

### 5. Prophet warning "Less data than horizon"
**Nguy√™n nh√¢n:** D·ªØ li·ªáu qu√° √≠t (< 2 tu·∫ßn)
**Gi·∫£i ph√°p:** B√¨nh th∆∞·ªùng, cross-validation s·∫Ω skip nh∆∞ng forecast v·∫´n ch·∫°y

---

## üìä GI·∫¢I TH√çCH KI·∫æN TR√öC

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LAMBDA ARCHITECTURE                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ BATCH LAYER ‚îÇ     ‚îÇ SPEED LAYER ‚îÇ     ‚îÇSERVING LAYER‚îÇ       ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ             ‚îÇ     ‚îÇ             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ week6_      ‚îÇ     ‚îÇ Kafka +     ‚îÇ     ‚îÇ week6_      ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ backfill.py ‚îÇ     ‚îÇ Spark       ‚îÇ     ‚îÇ merge.py    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ Streaming   ‚îÇ     ‚îÇ             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Binance API ‚îÇ     ‚îÇ             ‚îÇ     ‚îÇ Merge ‚Üí     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Üí Gap data  ‚îÇ     ‚îÇ Real-time   ‚îÇ     ‚îÇ Prophet     ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ         ‚îÇ                   ‚îÇ                   ‚îÇ               ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                             ‚ñº                                   ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ
‚îÇ                    ‚îÇ  FORECAST   ‚îÇ                              ‚îÇ
‚îÇ                    ‚îÇ  prophet_   ‚îÇ                              ‚îÇ
‚îÇ                    ‚îÇ  train.py   ‚îÇ                              ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ CHECKLIST TR∆Ø·ªöC KHI THI

- [ ] Docker Desktop ƒë√£ c√†i v√† ch·∫°y
- [ ] C√≥ k·∫øt n·ªëi Internet (ƒë·ªÉ fetch Binance API)
- [ ] ƒê√£ test th·ª≠ √≠t nh·∫•t 1 l·∫ßn tr∆∞·ªõc khi thi
- [ ] Bi·∫øt c√°ch x·ª≠ l√Ω c√°c l·ªói th∆∞·ªùng g·∫∑p
- [ ] Hi·ªÉu workflow: Backfill ‚Üí Kafka ‚Üí Producer ‚Üí Merge ‚Üí Forecast

---

## üìù GHI CH√ö

- **Th·ªùi gian ch·∫°y:** Kho·∫£ng 5-10 ph√∫t cho to√†n b·ªô workflow
- **Backup t·ª± ƒë·ªông:** M·ªói l·∫ßn ch·∫°y `prophet_train.py`, bi·ªÉu ƒë·ªì c≈© s·∫Ω ƒë∆∞·ª£c backup sang `*_old/`
- **So s√°nh k·∫øt qu·∫£:** C√≥ th·ªÉ so s√°nh `week4_visualizations/` (m·ªõi) v·ªõi `week4_visualizations_old/` (c≈©)

---

*T·∫°o b·ªüi: Big Data Project - Week 6 Lambda Architecture*
*C·∫≠p nh·∫≠t: 03/12/2025*

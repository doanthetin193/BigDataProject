# Gi·∫£i th√≠ch chi ti·∫øt: docker-compose.yml

**File:** `week6_streaming/docker-compose.yml`  
**Ch·ª©c nƒÉng:** Infrastructure setup - Kafka + Zookeeper cho Speed Layer  
**T√°c gi·∫£:** ƒêo√†n Th·∫ø T√≠n  
**Ng√†y:** Week 6 - Lambda Architecture

---

## üìã M·ª•c l·ª•c
1. [Docker Compose Overview](#1-docker-compose-overview)
2. [Version v√† Services](#2-version-v√†-services)
3. [Zookeeper Service](#3-zookeeper-service)
4. [Kafka Service](#4-kafka-service)
5. [Networks](#5-networks)
6. [Volumes](#6-volumes)
7. [C√°ch S·ª≠ D·ª•ng](#7-c√°ch-s·ª≠-d·ª•ng)
8. [T√≥m t·∫Øt](#t√≥m-t·∫Øt-t·ªïng-quan)

---

## 1. Docker Compose Overview

### Docker Compose l√† g√¨?
**Docker Compose** l√† tool ƒë·ªÉ define v√† run **multi-container Docker applications**.

**T·∫°i sao d√πng Docker Compose?**
- **Single file:** Define t·∫•t c·∫£ services trong 1 file YAML
- **One command:** Start/stop t·∫•t c·∫£ containers: `docker-compose up -d`
- **Networking:** Auto t·∫°o network cho containers communicate
- **Dependencies:** Manage startup order (`depends_on`)

**Alternative (kh√¥ng d√πng Docker Compose):**
```bash
# Ph·∫£i ch·∫°y 2 commands ri√™ng:
docker run -d --name zookeeper confluentinc/cp-zookeeper:7.5.0
docker run -d --name kafka --link zookeeper confluentinc/cp-kafka:7.5.0
# R·∫•t ph·ª©c t·∫°p v·ªõi nhi·ªÅu options!
```

**V·ªõi Docker Compose:**
```bash
# Ch·ªâ 1 command:
docker-compose up -d
```

---

## 2. Version v√† Services

### D√≤ng 1: Version
```yaml
version: '3.8'
```
**Gi·∫£i th√≠ch:**
- **Docker Compose file format version:** 3.8
- **Supported features:**
  - Services, Networks, Volumes
  - Healthchecks
  - Depends_on
  - Named volumes
- **Compatibility:** Docker Engine 19.03.0+

**Version history:**
| Version | Released | Key Features |
|---------|----------|--------------|
| 3.0 | 2016 | Basic services |
| 3.4 | 2017 | Long syntax configs |
| 3.8 | 2019 | **Current stable** |

---

### D√≤ng 3: Services
```yaml
services:
```
**Gi·∫£i th√≠ch:**
- **Services:** Danh s√°ch containers c·∫ßn ch·∫°y
- File n√†y c√≥ **2 services:**
  1. `zookeeper`: Coordination service
  2. `kafka`: Message broker

---

## 3. Zookeeper Service

### D√≤ng 4-6: Service Definition
```yaml
  # Zookeeper - Qu·∫£n l√Ω Kafka cluster
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
```
**Gi·∫£i th√≠ch:**

#### Service name: `zookeeper`
- T√™n service (d√πng trong `depends_on`, DNS)
- Containers kh√°c c√≥ th·ªÉ connect b·∫±ng hostname `zookeeper`

#### `image: confluentinc/cp-zookeeper:7.5.0`
- **Docker image:** Confluent Platform Zookeeper
- **Version:** 7.5.0 (latest stable)
- **Source:** Docker Hub (auto download n·∫øu ch∆∞a c√≥)

---

### Zookeeper l√† g√¨?

**Zookeeper** = **Coordination service** cho distributed systems.

**Vai tr√≤ trong Kafka:**
- **Cluster management:** Qu·∫£n l√Ω Kafka brokers
- **Leader election:** Ch·ªçn leader cho m·ªói partition
- **Configuration management:** L∆∞u configs, metadata
- **Synchronization:** ƒê·ªìng b·ªô state gi·ªØa brokers

**Analogy:**
- Kafka = Workers (x·ª≠ l√Ω messages)
- Zookeeper = Manager (qu·∫£n l√Ω workers)

**T·∫°i sao c·∫ßn Zookeeper?**
- Kafka **kh√¥ng th·ªÉ ch·∫°y standalone** (c·∫ßn Zookeeper)
- Zookeeper track:
  - Broker n√†o ƒëang online?
  - Partition n√†o ·ªü broker n√†o?
  - Consumer group offsets (legacy)

**Kafka future:**
- **KRaft mode (Kafka 3.0+):** Kh√¥ng c·∫ßn Zookeeper
- **Hi·ªán t·∫°i:** V·∫´n recommend d√πng Zookeeper (stable)

---

### D√≤ng 7: Container Name
```yaml
    container_name: zookeeper
```
**Gi·∫£i th√≠ch:**
- **Container name:** `zookeeper` (khi ch·∫°y `docker ps`)
- **Default behavior:** Docker Compose auto generate name
  - Format: `{project}_{service}_{index}`
  - V√≠ d·ª•: `week6_streaming_zookeeper_1`
- **Set c·ªë ƒë·ªãnh:** D·ªÖ reference (`docker logs zookeeper`)

---

### D√≤ng 8-11: Environment Variables
```yaml
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
```
**Gi·∫£i th√≠ch:**

#### `ZOOKEEPER_CLIENT_PORT: 2181`
- **Client port:** Port ƒë·ªÉ Kafka connect v√†o Zookeeper
- **Default:** 2181 (standard Zookeeper port)
- **Usage:** Kafka connect via `zookeeper:2181`

#### `ZOOKEEPER_TICK_TIME: 2000`
- **Tick time:** 2000 milliseconds (2 gi√¢y)
- **ƒê·ªãnh nghƒ©a:** Basic time unit c·ªßa Zookeeper
- **D√πng ƒë·ªÉ:**
  - Session timeout: 2 √ó tick_time = 4s
  - Heartbeat interval: 1 √ó tick_time = 2s
- **T·∫°i sao 2000ms?**
  - C√¢n b·∫±ng gi·ªØa responsiveness v√† stability
  - Qu√° nh·ªè ‚Üí False positives (t∆∞·ªüng node ch·∫øt)
  - Qu√° l·ªõn ‚Üí Slow failure detection

---

### D√≤ng 12-13: Port Mapping
```yaml
    ports:
      - "2181:2181"
```
**Gi·∫£i th√≠ch:**

#### Format: `"HOST:CONTAINER"`
- **Host port:** 2181 (m√°y local)
- **Container port:** 2181 (inside Docker)
- **Mapping:** localhost:2181 ‚Üí container:2181

#### T·∫°i sao expose port?
- **Producer/Consumer t·ª´ host:** Connect qua `localhost:2181`
- **Monitoring tools:** Check Zookeeper health
- **Debugging:** Manual queries v·ªõi zkCli

**V√≠ d·ª•:**
```bash
# T·ª´ host machine (outside Docker):
nc -zv localhost 2181
# Connection to localhost 2181 port [tcp/*] succeeded!
```

---

### D√≤ng 14-15: Network
```yaml
    networks:
      - crypto-network
```
**Gi·∫£i th√≠ch:**
- Join network `crypto-network`
- Kafka c≈©ng join network n√†y ‚Üí Communicate ƒë∆∞·ª£c

---

## 4. Kafka Service

### D√≤ng 17-19: Service Definition
```yaml
  # Kafka - Message broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
```
**Gi·∫£i th√≠ch:**

#### Service name: `kafka`
- Hostname: `kafka` (DNS trong Docker network)

#### `image: confluentinc/cp-kafka:7.5.0`
- **Confluent Platform Kafka:** Enterprise distribution
- **Version:** 7.5.0 (match v·ªõi Zookeeper)
- **Features:**
  - Apache Kafka core
  - Additional tools (Schema Registry, etc.)
  - Production-ready configs

---

### Kafka l√† g√¨?

**Kafka** = **Distributed streaming platform** / **Message broker**.

**Core concepts:**
- **Producers:** Send messages
- **Consumers:** Read messages
- **Topics:** Categories (v√≠ d·ª•: `crypto-prices`)
- **Partitions:** Parallel processing
- **Brokers:** Kafka servers

**Use cases:**
- **Real-time streaming:** Stock prices, IoT sensors
- **Event sourcing:** User activity logs
- **Message queue:** Decouple microservices
- **Log aggregation:** Centralized logging

**T·∫°i sao d√πng Kafka?**
- **High throughput:** Millions messages/second
- **Scalable:** Add brokers horizontally
- **Durable:** Persist messages to disk
- **Fault-tolerant:** Replication, no data loss

---

### D√≤ng 20: Container Name
```yaml
    container_name: kafka
```
**Gi·∫£i th√≠ch:** Container name `kafka` (thay v√¨ auto-generated).

---

### D√≤ng 21-22: Dependencies
```yaml
    depends_on:
      - zookeeper
```
**Gi·∫£i th√≠ch:**

#### `depends_on: [zookeeper]`
- **Startup order:** Start Zookeeper tr∆∞·ªõc Kafka
- **T·∫°i sao?** Kafka c·∫ßn connect Zookeeper l√∫c startup

#### Limitation
- `depends_on` ch·ªâ ƒë·∫£m b·∫£o **start order**
- **KH√îNG ƒë·ª£i** Zookeeper ready (healthy)
- **Risk:** Kafka c√≥ th·ªÉ start tr∆∞·ªõc khi Zookeeper ready ‚Üí Fail

#### Solution (production)
```yaml
depends_on:
  zookeeper:
    condition: service_healthy
```
- C·∫ßn define `healthcheck` cho Zookeeper

---

### D√≤ng 23-25: Port Mapping
```yaml
    ports:
      - "9092:9092"
      - "9093:9093"
```
**Gi·∫£i th√≠ch:**

#### Port 9092
- **PLAINTEXT listener:** External connections (t·ª´ host)
- **Usage:** Producer, Consumer t·ª´ host connect qua `localhost:9092`
- **Example:**
  ```python
  producer = KafkaProducer(bootstrap_servers=['localhost:9092'])
  ```

#### Port 9093
- **PLAINTEXT_INTERNAL listener:** Internal connections (gi·ªØa containers)
- **Usage:** Kafka consumers trong Docker network connect qua `kafka:9093`
- **Example:** N·∫øu c√≥ Spark container c√πng network

#### T·∫°i sao 2 ports?
- **9092:** Host ‚Üí Kafka (external)
- **9093:** Container ‚Üí Kafka (internal)
- **L√Ω do:** Docker networking isolation

---

### D√≤ng 26-35: Environment Variables

#### D√≤ng 27: Broker ID
```yaml
    environment:
      KAFKA_BROKER_ID: 1
```
**Gi·∫£i th√≠ch:**
- **Broker ID:** Unique identifier cho Kafka broker
- **Value:** 1 (single broker)
- **Multi-broker cluster:** M·ªói broker c·∫ßn ID kh√°c nhau (1, 2, 3, ...)

---

#### D√≤ng 28: Zookeeper Connect
```yaml
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
```
**Gi·∫£i th√≠ch:**
- **Zookeeper address:** `zookeeper:2181`
  - `zookeeper`: Hostname (Docker DNS)
  - `2181`: Zookeeper client port
- **T·∫°i sao d√πng hostname?**
  - Containers trong c√πng network resolve DNS
  - `zookeeper` ‚Üí IP c·ªßa Zookeeper container

---

#### D√≤ng 29: Advertised Listeners
```yaml
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9093
```
**Gi·∫£i th√≠ch:**

**Advertised listeners** = Addresses m√† Kafka **qu·∫£ng c√°o** cho clients.

**Format:** `LISTENER_NAME://HOST:PORT`

#### `PLAINTEXT://localhost:9092`
- **Listener name:** PLAINTEXT
- **Address:** localhost:9092
- **Purpose:** External clients (Producer, Consumer t·ª´ host)
- **Why localhost?**
  - Client ·ªü host machine
  - Connect via `localhost:9092`

#### `PLAINTEXT_INTERNAL://kafka:9093`
- **Listener name:** PLAINTEXT_INTERNAL
- **Address:** kafka:9093
- **Purpose:** Internal clients (containers trong Docker network)
- **Why kafka?**
  - Client ·ªü Docker network
  - Connect via `kafka:9093`

**Flow:**
```
Producer (host) ‚Üí localhost:9092 ‚Üí Kafka container
  Kafka advertises: "Connect to localhost:9092"

Consumer (Docker) ‚Üí kafka:9093 ‚Üí Kafka container
  Kafka advertises: "Connect to kafka:9093"
```

---

#### D√≤ng 30: Listener Security Protocol Map
```yaml
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
```
**Gi·∫£i th√≠ch:**

**Security protocol map** = Mapping t·ª´ listener name ‚Üí protocol.

#### `PLAINTEXT:PLAINTEXT`
- Listener `PLAINTEXT` d√πng protocol `PLAINTEXT` (no encryption)

#### `PLAINTEXT_INTERNAL:PLAINTEXT`
- Listener `PLAINTEXT_INTERNAL` d√πng protocol `PLAINTEXT`

**Protocols available:**
- `PLAINTEXT`: No encryption, no auth (demo only)
- `SSL`: TLS encryption
- `SASL_PLAINTEXT`: Authentication, no encryption
- `SASL_SSL`: Authentication + TLS

**Production:**
```yaml
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: SSL:SSL,SASL_SSL:SASL_SSL
```

---

#### D√≤ng 31: Offsets Topic Replication Factor
```yaml
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```
**Gi·∫£i th√≠ch:**

#### `__consumer_offsets` topic
- **Internal topic:** L∆∞u consumer group offsets
- **Purpose:** Track consumer progress (ƒë√£ ƒë·ªçc ƒë·∫øn offset n√†o)

#### `REPLICATION_FACTOR: 1`
- **Replication:** 1 copy (no backup)
- **T·∫°i sao 1?** Single broker (no cluster)
- **Production (3 brokers):** `REPLICATION_FACTOR: 3`
  - 3 copies ‚Üí Fault tolerance
  - 1 broker ch·∫øt ‚Üí V·∫´n c√≤n 2 copies

---

#### D√≤ng 32: Transaction State Log Min ISR
```yaml
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
```
**Gi·∫£i th√≠ch:**

#### `__transaction_state` topic
- **Internal topic:** L∆∞u transaction states
- **Purpose:** Exactly-once semantics

#### `MIN_ISR: 1`
- **Min In-Sync Replicas:** T·ªëi thi·ªÉu 1 replica in-sync
- **Single broker:** Must be 1
- **Production:** `MIN_ISR: 2` (with 3 replicas)

---

#### D√≤ng 33: Transaction State Log Replication Factor
```yaml
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
```
**Gi·∫£i th√≠ch:**
- **Replication factor:** 1 copy
- **Reason:** Single broker

---

#### D√≤ng 34: Auto Create Topics
```yaml
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
```
**Gi·∫£i th√≠ch:**

#### `AUTO_CREATE_TOPICS_ENABLE: true`
- **Behavior:** T·ª± ƒë·ªông t·∫°o topic khi producer send message
- **Example:**
  ```python
  # Topic "crypto-prices" ch∆∞a t·ªìn t·∫°i
  producer.send("crypto-prices", value=data)
  # ‚Üí Kafka auto create topic "crypto-prices"
  ```

#### Default settings (auto-created topic)
- **Partitions:** 1
- **Replication factor:** 1
- **Retention:** 7 days

#### Production recommendation
```yaml
KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
```
- **Reason:** Explicit control (partitions, retention, ...)
- **Manually create:**
  ```bash
  kafka-topics --create \
    --topic crypto-prices \
    --partitions 3 \
    --replication-factor 2
  ```

#### Trong project n√†y: `true`
- **L√Ω do:** Demo ƒë∆°n gi·∫£n, kh√¥ng c·∫ßn manual setup

---

### D√≤ng 35-36: Network
```yaml
    networks:
      - crypto-network
```
**Gi·∫£i th√≠ch:**
- Join `crypto-network` (c√πng network v·ªõi Zookeeper)

---

### D√≤ng 37-38: Volumes
```yaml
    volumes:
      - kafka-data:/var/lib/kafka/data
```
**Gi·∫£i th√≠ch:**

#### Volume mapping
- **Named volume:** `kafka-data`
- **Mount point:** `/var/lib/kafka/data` (inside container)

#### T·∫°i sao c·∫ßn volume?
- **Persist data:** Messages kh√¥ng m·∫•t khi restart container
- **Without volume:** Data m·∫•t khi container removed

#### What's stored?
- **Topic data:** Messages
- **Partition logs:** Segment files
- **Indexes:** Offset indexes

#### Example
```bash
# Container removed
docker-compose down

# Data v·∫´n c√≤n trong volume
docker volume ls
# kafka-data

# Restart container
docker-compose up -d
# ‚Üí Data restored from volume
```

---

## 5. Networks

### D√≤ng 40-42: Network Definition
```yaml
networks:
  crypto-network:
    driver: bridge
```
**Gi·∫£i th√≠ch:**

#### Network name: `crypto-network`
- Custom network cho project

#### `driver: bridge`
- **Bridge network:** Default Docker network type
- **Features:**
  - Containers trong c√πng network communicate
  - DNS resolution (hostname ‚Üí IP)
  - Isolated t·ª´ host network

**Network topology:**
```
Host Network (192.168.1.x)
  ‚Üì
Docker Bridge Network (172.18.0.x)
  ‚îú‚îÄ‚îÄ zookeeper (172.18.0.2:2181)
  ‚îî‚îÄ‚îÄ kafka (172.18.0.3:9092, 9093)
```

**Communication:**
```
Kafka ‚Üí Zookeeper:
  kafka container connects to zookeeper:2181
  DNS resolves zookeeper ‚Üí 172.18.0.2

Producer (host) ‚Üí Kafka:
  localhost:9092 ‚Üí port mapping ‚Üí kafka:9092
```

---

## 6. Volumes

### D√≤ng 44-45: Volume Definition
```yaml
volumes:
  kafka-data:
```
**Gi·∫£i th√≠ch:**

#### Named volume: `kafka-data`
- **Managed by Docker:** Location auto-determined
- **Default path (Linux):** `/var/lib/docker/volumes/kafka-data/_data`
- **Default path (Windows):** `\\wsl$\docker-desktop-data\version-pack-data\community\docker\volumes\kafka-data\_data`

#### T·∫°i sao d√πng named volume?
- **Portable:** Kh√¥ng hardcode path
- **Managed:** Docker handles lifecycle
- **Backup friendly:** Easy to backup/restore

**Alternative: bind mount**
```yaml
volumes:
  - ./kafka-data:/var/lib/kafka/data
```
- **Bind mount:** Specific host path
- **Use case:** Need direct access to data

---

## 7. C√°ch S·ª≠ D·ª•ng

### **Start Services**
```bash
cd week6_streaming
docker-compose up -d
```
**Output:**
```
Creating network "crypto-network" with driver "bridge"
Creating volume "kafka-data" with default driver
Creating zookeeper ... done
Creating kafka     ... done
```

**Flags:**
- `-d`: Detached mode (background)
- Without `-d`: See logs in foreground

---

### **Check Status**
```bash
docker-compose ps
```
**Output:**
```
   Name                 Command            State                    Ports
---------------------------------------------------------------------------------
kafka        /etc/confluent/docker/run   Up      0.0.0.0:9092->9092/tcp,
                                                  0.0.0.0:9093->9093/tcp
zookeeper    /etc/confluent/docker/run   Up      0.0.0.0:2181->2181/tcp
```

---

### **View Logs**
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f kafka
docker-compose logs -f zookeeper
```

---

### **Stop Services**
```bash
docker-compose stop
```
- **Stop containers** (data v·∫´n c√≤n trong volumes)

---

### **Remove Containers**
```bash
docker-compose down
```
- **Stop v√† remove** containers
- **Keep volumes** (data kh√¥ng m·∫•t)

---

### **Remove Everything (including volumes)**
```bash
docker-compose down -v
```
- Remove containers + networks + volumes
- **Warning:** Data s·∫Ω m·∫•t!

---

### **Restart Services**
```bash
docker-compose restart
```

---

### **Exec into Container**
```bash
# Kafka container
docker exec -it kafka bash

# Zookeeper container
docker exec -it zookeeper bash
```

---

### **Create Topic Manually**
```bash
docker exec -it kafka kafka-topics \
  --create \
  --topic crypto-prices \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1
```

---

### **List Topics**
```bash
docker exec -it kafka kafka-topics \
  --list \
  --bootstrap-server localhost:9092
```

---

### **Consume Messages**
```bash
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic crypto-prices \
  --from-beginning
```

---

## 8. T√≥m t·∫Øt T·ªïng quan

## üéØ M·ª•c ƒë√≠ch File
File `docker-compose.yml` define infrastructure cho Speed Layer - Kafka message broker + Zookeeper coordination service ch·∫°y trong Docker containers.

---

## üìä Architecture

### **Services (2)**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              crypto-network (bridge)             ‚îÇ
‚îÇ                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    Zookeeper        ‚îÇ  ‚îÇ      Kafka       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Port: 2181         ‚îÇ‚Üê‚îÄ‚îÇ  Ports: 9092,    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Image: 7.5.0       ‚îÇ  ‚îÇ         9093     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Role: Coordinator  ‚îÇ  ‚îÇ  Image: 7.5.0    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  Role: Broker    ‚îÇ  ‚îÇ
‚îÇ                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                   ‚îÇ              ‚îÇ
‚îÇ                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                            ‚îÇ  kafka-data     ‚îÇ   ‚îÇ
‚îÇ                            ‚îÇ  (volume)       ‚îÇ   ‚îÇ
‚îÇ                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñ≤                           ‚ñ≤
         ‚îÇ :2181                     ‚îÇ :9092
         ‚îÇ                           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ       Host Machine          ‚îÇ         ‚îÇ
    ‚îÇ  websocket_producer.py      ‚îÇ  Spark  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîë Key Configurations

### **Zookeeper**
| Config | Value | Purpose |
|--------|-------|---------|
| `CLIENT_PORT` | 2181 | Kafka connection port |
| `TICK_TIME` | 2000ms | Heartbeat interval |
| Port mapping | 2181:2181 | Host access |

### **Kafka**
| Config | Value | Purpose |
|--------|-------|---------|
| `BROKER_ID` | 1 | Unique broker ID |
| `ZOOKEEPER_CONNECT` | zookeeper:2181 | Zookeeper address |
| `ADVERTISED_LISTENERS` | localhost:9092, kafka:9093 | Client addresses |
| `AUTO_CREATE_TOPICS` | true | Auto create topics |
| Port mapping | 9092:9092, 9093:9093 | External/Internal access |
| Volume | kafka-data | Data persistence |

---

## üí° Design Decisions

### **1. Single Broker Setup**
```yaml
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
```
- **Reason:** Demo/Development environment
- **Production:** 3+ brokers with replication factor 3

### **2. Auto Create Topics**
```yaml
KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
```
- **Reason:** Simplicity (no manual setup)
- **Production:** `false` (explicit control)

### **3. PLAINTEXT Security**
```yaml
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
```
- **Reason:** Local development
- **Production:** SSL/SASL_SSL

### **4. Named Volume**
```yaml
volumes:
  - kafka-data:/var/lib/kafka/data
```
- **Reason:** Data persistence across restarts
- **Alternative:** Bind mount for direct access

---

## üöÄ Common Commands

```bash
# Start
docker-compose up -d

# Status
docker-compose ps

# Logs
docker-compose logs -f kafka

# Stop
docker-compose stop

# Remove (keep data)
docker-compose down

# Remove (delete data)
docker-compose down -v

# Restart
docker-compose restart
```

---

## üîß Troubleshooting

### **1. Kafka Not Starting**
**Error:** `Connection to Zookeeper failed`  
**Solution:**
```bash
# Check Zookeeper healthy
docker logs zookeeper

# Restart both
docker-compose restart
```

---

### **2. Port Already in Use**
**Error:** `Bind for 0.0.0.0:9092 failed: port is already allocated`  
**Solution:**
```bash
# Check process using port
netstat -ano | findstr :9092

# Kill process or change port in docker-compose.yml
ports:
  - "9094:9092"  # Map to different host port
```

---

### **3. Cannot Connect from Host**
**Error:** `Connection refused: localhost:9092`  
**Solution:**
```bash
# Check advertised listeners
docker exec kafka cat /etc/kafka/server.properties | grep advertised

# Should see: advertised.listeners=PLAINTEXT://localhost:9092

# Check port mapping
docker ps | grep kafka
# Should see: 0.0.0.0:9092->9092/tcp
```

---

### **4. Data Lost After Restart**
**Problem:** Messages disappear  
**Solution:**
```bash
# Check volume exists
docker volume ls | grep kafka-data

# If missing, recreate with volume
docker-compose down
docker-compose up -d

# Verify volume mounted
docker inspect kafka | grep Mounts -A 20
```

---

### **5. Zookeeper Connection Timeout**
**Error:** `Timed out waiting for connection while in state: CONNECTING`  
**Solution:**
```bash
# Increase tick time
ZOOKEEPER_TICK_TIME: 4000

# Or restart services
docker-compose restart zookeeper
sleep 10
docker-compose restart kafka
```

---

## üìà Performance Tuning

### **Development (Current)**
```yaml
# Single broker, minimal resources
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

### **Production**
```yaml
# Multi-broker cluster
version: '3.8'
services:
  kafka1:
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
  kafka2:
    environment:
      KAFKA_BROKER_ID: 2
  kafka3:
    environment:
      KAFKA_BROKER_ID: 3
```

---

## üéì Key Technologies

- **Docker Compose:** Multi-container orchestration
- **Confluent Platform:** Enterprise Kafka distribution
- **Zookeeper:** Distributed coordination
- **Kafka:** Distributed streaming platform
- **Bridge Network:** Container networking
- **Named Volumes:** Data persistence

---

## üîó Integration

### **Project Flow**
```
1. Start infrastructure:
   docker-compose up -d
   
2. Producer sends data:
   python websocket_producer.py
   ‚Üì (Kafka topic: crypto-prices)
   
3. Consumer reads data:
   python kafka_batch_reader.py
   python spark_streaming_consumer.py
   
4. Merge layers:
   python week6_merge.py
```

---

## üìä Comparison: Dev vs Prod

| Aspect | Development (File n√†y) | Production |
|--------|----------------------|------------|
| **Brokers** | 1 | 3+ |
| **Zookeeper** | 1 | 3+ (ensemble) |
| **Replication** | 1 | 3 |
| **Security** | PLAINTEXT | SSL/SASL |
| **Auto-create** | ‚úÖ Enabled | ‚ùå Disabled |
| **Resources** | Minimal | High (tuned) |
| **Monitoring** | Logs only | Prometheus, Grafana |
| **Backup** | Manual | Automated |

---

## ‚ö†Ô∏è Important Notes

### **1. Data Persistence**
- Volume `kafka-data` persist data
- `docker-compose down` **gi·ªØ** data
- `docker-compose down -v` **x√≥a** data

### **2. Network Isolation**
- Containers communicate via `crypto-network`
- Host access via port mapping (9092, 2181)

### **3. Startup Order**
- Zookeeper starts first
- Kafka starts after (depends_on)
- Wait ~10s for full initialization

### **4. Production Readiness**
- File n√†y cho **development/demo**
- Production c·∫ßn:
  - Multi-broker setup
  - SSL/SASL security
  - Resource limits
  - Monitoring
  - Backup strategy

---

**T√°c gi·∫£:** ƒêo√†n Th·∫ø T√≠n  
**MSSV:** 4551190056  
**File:** `week6_streaming/docker-compose.yml`  
**Lines:** 45 d√≤ng YAML  
**M·ª•c ƒë√≠ch:** Infrastructure setup cho Speed Layer - Kafka + Zookeeper trong Docker

---

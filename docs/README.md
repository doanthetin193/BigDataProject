# ğŸ“‚ BigDataProject - Cáº¥u TrÃºc Dá»± Ãn

## ğŸ—‚ï¸ Cáº¥u TrÃºc ThÆ° Má»¥c

```
D:\BigDataProject/
â”‚
â”œâ”€â”€ ğŸ“œ scripts/                    # All Python scripts
â”‚   â”œâ”€â”€ preprocessing/             # Data preparation
â”‚   â”‚   â”œâ”€â”€ convert_to_parquet.py  # CSV â†’ Parquet conversion
â”‚   â”‚   â”œâ”€â”€ clean_parquet.py       # Remove duplicates
â”‚   â”‚   â”œâ”€â”€ preprocess_step1.py    # 1-min â†’ daily aggregation
â”‚   â”‚   â””â”€â”€ preprocess_step2.py    # Forward fill + MA calculation
â”‚   â”‚
â”‚   â”œâ”€â”€ lambda_batch/              # Batch Layer (Lambda Architecture)
â”‚   â”‚   â”œâ”€â”€ week6_backfill.py      # Regular backfill (gap < 30 days)
â”‚   â”‚   â”œâ”€â”€ week6_backfill_batch.py # Large gap backfill (> 30 days)
â”‚   â”‚   â”œâ”€â”€ week6_merge.py         # Serving Layer merge
â”‚   â”‚   â””â”€â”€ week6_merge_temp.py    # One-time merge utility
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_models/                 # Machine Learning
â”‚   â”‚   â””â”€â”€ prophet_train.py       # Prophet forecasting
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilities & debugging
â”‚       â”œâ”€â”€ check_data.py          # Data verification
â”‚       â”œâ”€â”€ check_forecast.py      # Forecast results check
â”‚       â”œâ”€â”€ final_verification.py  # System verification
â”‚       â””â”€â”€ cleanup_analysis.py    # Cleanup recommendations
â”‚
â”œâ”€â”€ ğŸ“š docs/                       # Documentation
â”‚   â”œâ”€â”€ README.md                  # This file
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md         # Complete project summary
â”‚   â”œâ”€â”€ proposed_structure.md      # Directory structure proposal
â”‚   â”œâ”€â”€ WEEK6_01_TONG_QUAN.md      # Lambda Architecture overview
â”‚   â”œâ”€â”€ WEEK6_02_BATCH_LAYER.md    # Batch layer docs
â”‚   â”œâ”€â”€ WEEK6_03_SPEED_LAYER.md    # Speed layer docs
â”‚   â”œâ”€â”€ WEEK6_04_SERVING_LAYER.md  # Serving layer docs
â”‚   â”œâ”€â”€ WEEK6_HUONG_DAN_CHAY.md    # Running instructions
â”‚   â”œâ”€â”€ WEEK6_LAMBDA_ARCHITECTURE.md # Architecture details
â”‚   â””â”€â”€ WEEK6_SPARK_STREAMING_CONSUMER_GIAI_THICH.md
â”‚
â”œâ”€â”€ ğŸ’¾ data/                       # Raw CSV data
â”‚   â”œâ”€â”€ btc/
â”‚   â”‚   â””â”€â”€ BTCUSDT_1min_2012-2025.csv (7.2M rows)
â”‚   â””â”€â”€ eth/
â”‚       â””â”€â”€ ETHUSDT_1min_2017-2025.csv (4M+ rows)
â”‚
â”œâ”€â”€ ğŸ“Š data_parquet/               # Parquet format (partitioned)
â”‚   â”œâ”€â”€ btc_clean/                 # year=YYYY/month=MM/
â”‚   â””â”€â”€ eth_clean/                 # year=YYYY/month=MM/
â”‚
â”œâ”€â”€ ğŸ“ˆ data_analysis/              # Processed data & results
â”‚   â”œâ”€â”€ daily_filled/              # 8,140 daily rows (OHLCV + MA)
â”‚   â”œâ”€â”€ prophet_input/             # 8,140 rows (ds, y, symbol)
â”‚   â”œâ”€â”€ week4_forecasts/           # Prophet forecast parquet
â”‚   â”œâ”€â”€ week4_metrics/             # Model performance metrics
â”‚   â”œâ”€â”€ week4_results/             # Actual vs predicted CSV
â”‚   â””â”€â”€ week4_visualizations/      # Interactive HTML charts
â”‚
â”œâ”€â”€ ğŸŒŠ week6_streaming/            # Speed Layer (Lambda Architecture)
â”‚   â”œâ”€â”€ docker-compose.yml         # Kafka setup
â”‚   â”œâ”€â”€ websocket_producer.py      # Binance WebSocket â†’ Kafka
â”‚   â”œâ”€â”€ spark_streaming_consumer.py # Kafka â†’ Spark Streaming
â”‚   â”œâ”€â”€ checkpoint_spark/          # Spark checkpoints
â”‚   â””â”€â”€ streaming_output_spark/    # Real-time aggregations
â”‚
â”œâ”€â”€ ğŸ”§ hadoop/                     # Hadoop binaries (for Spark on Windows)
â”‚   â””â”€â”€ bin/
â”‚
â””â”€â”€ ğŸ“ logs/                       # Application logs
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ **Preprocessing (First Time Setup)**
```bash
cd scripts/preprocessing
python convert_to_parquet.py  # CSV â†’ Parquet
python clean_parquet.py        # Remove duplicates
python preprocess_step1.py     # Aggregate to daily
python preprocess_step2.py     # Forward fill + MA
```

### 2ï¸âƒ£ **Train Prophet Model**
```bash
cd scripts/ml_models
python prophet_train.py
```

### 3ï¸âƒ£ **Batch Layer - Backfill Missing Data**

**Regular update (< 30 days gap):**
```bash
cd scripts/lambda_batch
python week6_backfill.py
```

**Large update (> 30 days gap):**
```bash
cd scripts/lambda_batch
python week6_backfill_batch.py
python week6_merge_temp.py
```

### 4ï¸âƒ£ **Speed Layer - Real-time Streaming**
```bash
cd week6_streaming
docker-compose up -d           # Start Kafka
python websocket_producer.py   # Producer (background)
python spark_streaming_consumer.py  # Consumer
```

### 5ï¸âƒ£ **Serving Layer - Query Unified View**
```bash
cd scripts/lambda_batch
python week6_merge.py
```

---

## ğŸ“Š Data Flow

```
CSV (1-min raw)
    â†“
Parquet (partitioned)
    â†“
daily_raw (OHLCV)
    â†“
daily_filled (OHLCV + MA7/MA30) â† SOURCE
    â†“
prophet_input (ds, y, symbol) â† DERIVED
    â†“
Prophet Model â†’ Forecasts
```

---

## ğŸ—ï¸ Lambda Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       SERVING LAYER                 â”‚
â”‚    (week6_merge.py)                 â”‚
â”‚  Batch View + Real-time View        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚ BATCH   â”‚    â”‚  SPEED   â”‚
    â”‚ LAYER   â”‚    â”‚  LAYER   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Batch Layer:**
- Historical data processing
- Immutable master dataset
- Backfill automation

**Speed Layer:**
- Real-time data ingestion
- WebSocket â†’ Kafka â†’ Spark Streaming
- Low-latency updates

**Serving Layer:**
- Merge Batch + Speed views
- Unified query interface
- Consistent data model

---

## ğŸ“ˆ Results

**Dataset:**
- 8,140 daily rows (BTC: 5,097 + ETH: 3,043)
- Date range: 2012-01-01 â†’ 2025-12-14
- Complete with MA7/MA30 indicators

**Model Performance:**
- BTCUSDT: MAPE 3.36% (CV)
- ETHUSDT: MAPE 3.90% (CV)
- Quality: âœ… GOOD (< 5%)

**Visualizations:**
- Interactive Plotly charts in `data_analysis/week4_visualizations/`
- Actual vs predicted CSVs in `data_analysis/week4_results/`

---

## ğŸ› ï¸ Utilities

**Verification:**
```bash
cd scripts/utils
python final_verification.py  # Check entire system
python check_data.py          # Verify data completeness
python check_forecast.py      # Inspect forecast results
```

**Cleanup:**
```bash
cd scripts/utils
python cleanup_analysis.py    # Analyze disk usage
```

---

## ğŸ“š Documentation

Xem thÃªm chi tiáº¿t trong `docs/`:

- **PROJECT_SUMMARY.md**: Tá»•ng quan toÃ n bá»™ dá»± Ã¡n
- **WEEK6_01_TONG_QUAN.md**: Lambda Architecture overview
- **WEEK6_HUONG_DAN_CHAY.md**: HÆ°á»›ng dáº«n cháº¡y tá»«ng bÆ°á»›c
- **WEEK6_02_BATCH_LAYER.md**: Chi tiáº¿t Batch Layer
- **WEEK6_03_SPEED_LAYER.md**: Chi tiáº¿t Speed Layer
- **WEEK6_04_SERVING_LAYER.md**: Chi tiáº¿t Serving Layer

---

## âœ… System Status

Cháº¡y Ä‘á»ƒ kiá»ƒm tra:
```bash
cd scripts/utils
python final_verification.py
```

Káº¿t quáº£ mong Ä‘á»£i:
```
âœ… Data up to date
âœ… Prophet input schema
âœ… Model quality (MAPE < 5%)
âœ… Lambda files exist
âœ… Schema consistency

âœ… ALL SYSTEMS READY!
```

---

## ğŸ”— Links

- Binance API: https://binance-docs.github.io/apidocs/
- Prophet: https://facebook.github.io/prophet/
- PySpark: https://spark.apache.org/docs/latest/api/python/

---

*Last updated: 2025-12-14*

# ğŸ“˜ WEEK 6 - PHáº¦N 4: SERVING LAYER (Merge + Forecast)

## ğŸ“‘ Má»¥c lá»¥c
1. [Má»¥c Ä‘Ã­ch cá»§a Serving Layer](#1-má»¥c-Ä‘Ã­ch-cá»§a-serving-layer)
2. [Kiáº¿n trÃºc Serving Layer](#2-kiáº¿n-trÃºc-serving-layer)
3. [week6_merge.py - Giáº£i thÃ­ch chi tiáº¿t](#3-week6_mergepy---giáº£i-thÃ­ch-chi-tiáº¿t)
4. [prophet_train.py - Giáº£i thÃ­ch chi tiáº¿t](#4-prophet_trainpy---giáº£i-thÃ­ch-chi-tiáº¿t)
5. [Káº¿t ná»‘i 3 Layers](#5-káº¿t-ná»‘i-3-layers)
6. [Output vÃ  Káº¿t quáº£](#6-output-vÃ -káº¿t-quáº£)
7. [CÃ¢u há»i thÆ°á»ng gáº·p](#7-cÃ¢u-há»i-thÆ°á»ng-gáº·p)
8. [Tá»•ng káº¿t Week 6](#8-tá»•ng-káº¿t-week-6)

---

## 1. Má»¥c Ä‘Ã­ch cá»§a Serving Layer

### 1.1. Vai trÃ² trong Lambda Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAMBDA ARCHITECTURE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚        BATCH LAYER              SPEED LAYER                         â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚        â”‚Historicalâ”‚              â”‚Real-timeâ”‚                        â”‚
â”‚        â”‚  Data    â”‚              â”‚  Data   â”‚                        â”‚
â”‚        â”‚ (chÃ­nh   â”‚              â”‚ (nhanh) â”‚                        â”‚
â”‚        â”‚  xÃ¡c)    â”‚              â”‚         â”‚                        â”‚
â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                        â”‚
â”‚             â”‚                         â”‚                             â”‚
â”‚             â”‚                         â”‚                             â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                        â”‚                                            â”‚
â”‚                        â–¼                                            â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚               â”‚ SERVING LAYER  â”‚ â† ÄÃ‚Y LÃ€ SERVING LAYER            â”‚
â”‚               â”‚                â”‚                                   â”‚
â”‚               â”‚ â€¢ MERGE data   â”‚                                   â”‚
â”‚               â”‚ â€¢ DEDUPLICATE  â”‚                                   â”‚
â”‚               â”‚ â€¢ RECOMPUTE    â”‚                                   â”‚
â”‚               â”‚ â€¢ FORECAST     â”‚                                   â”‚
â”‚               â”‚ â€¢ VISUALIZE    â”‚                                   â”‚
â”‚               â”‚                â”‚                                   â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                        â”‚                                            â”‚
â”‚                        â–¼                                            â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚               â”‚    OUTPUT      â”‚                                   â”‚
â”‚               â”‚  â€¢ Forecasts   â”‚                                   â”‚
â”‚               â”‚  â€¢ Charts      â”‚                                   â”‚
â”‚               â”‚  â€¢ Metrics     â”‚                                   â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2. Äáº·c Ä‘iá»ƒm cá»§a Serving Layer

```
Serving Layer chá»‹u trÃ¡ch nhiá»‡m:

1. MERGE dá»¯ liá»‡u tá»« Batch + Speed Layer
   â””â”€â”€ Union â†’ Deduplicate â†’ Sort

2. DEDUPLICATE loáº¡i bá» trÃ¹ng láº·p
   â””â”€â”€ CÃ¹ng (symbol, date) â†’ Giá»¯ 1 báº£n

3. RECOMPUTE cÃ¡c metrics
   â””â”€â”€ TÃ­nh láº¡i MA7, MA30 cho timeline má»›i

4. SERVE cho downstream applications
   â””â”€â”€ Prophet forecasting
   â””â”€â”€ Visualization
   â””â”€â”€ Analytics

5. ANSWER queries
   â””â”€â”€ Latest data always available
```

### 1.3. Táº¡i sao cáº§n Serving Layer?

```
Váº¥n Ä‘á»: Batch Layer vÃ  Speed Layer cÃ³ data riÃªng biá»‡t

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  BATCH LAYER (daily_filled/)                                       â”‚
â”‚  â”œâ”€â”€ 2012-01-01 â†’ 2025-11-23                                       â”‚
â”‚  â””â”€â”€ ChÃ­nh xÃ¡c, Ä‘áº§y Ä‘á»§                                             â”‚
â”‚                                                                     â”‚
â”‚  SPEED LAYER (streaming_output_spark/daily/)                       â”‚
â”‚  â”œâ”€â”€ 2025-11-24 â†’ 2025-12-03 (today)                               â”‚
â”‚  â””â”€â”€ Real-time, cÃ³ thá»ƒ trÃ¹ng                                       â”‚
â”‚                                                                     â”‚
â”‚  Äá»ƒ forecast, cáº§n:                                                  â”‚
â”‚  â”œâ”€â”€ Timeline liÃªn tá»¥c tá»« 2012 â†’ 2025-12-03                        â”‚
â”‚  â”œâ”€â”€ KhÃ´ng cÃ³ gaps                                                 â”‚
â”‚  â””â”€â”€ KhÃ´ng cÃ³ duplicates                                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Giáº£i phÃ¡p: Serving Layer merge táº¥t cáº£

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  SERVING LAYER                                                      â”‚
â”‚                                                                     â”‚
â”‚  Input 1: Batch Layer data                                         â”‚
â”‚  Input 2: Speed Layer data                                         â”‚
â”‚                                                                     â”‚
â”‚  Output: Unified timeline                                           â”‚
â”‚  â”œâ”€â”€ 2012-01-01 â†’ 2025-12-03                                       â”‚
â”‚  â”œâ”€â”€ No gaps                                                        â”‚
â”‚  â”œâ”€â”€ No duplicates                                                  â”‚
â”‚  â””â”€â”€ MA7/MA30 recomputed                                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Kiáº¿n trÃºc Serving Layer

### 2.1. Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SERVING LAYER DATA FLOW                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚      BATCH LAYER                    SPEED LAYER                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ daily_filled/   â”‚            â”‚streaming_output_â”‚                â”‚
â”‚  â”‚                 â”‚            â”‚  spark/daily/   â”‚                â”‚
â”‚  â”‚ BTCUSDT:        â”‚            â”‚                 â”‚                â”‚
â”‚  â”‚ 2012 â†’ 2025-11  â”‚            â”‚ BTCUSDT:        â”‚                â”‚
â”‚  â”‚ ~4700 days      â”‚            â”‚ 2025-11 â†’ 12    â”‚                â”‚
â”‚  â”‚                 â”‚            â”‚ ~10 days        â”‚                â”‚
â”‚  â”‚ ETHUSDT:        â”‚            â”‚                 â”‚                â”‚
â”‚  â”‚ 2017 â†’ 2025-11  â”‚            â”‚ ETHUSDT:        â”‚                â”‚
â”‚  â”‚ ~2900 days      â”‚            â”‚ ~10 days        â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚           â”‚                              â”‚                          â”‚
â”‚           â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                          â”‚
â”‚           â”‚     â”‚                    â”‚   â”‚                          â”‚
â”‚           â””â”€â”€â”€â”€â–ºâ”‚  week6_merge.py    â”‚â—„â”€â”€â”˜                          â”‚
â”‚                 â”‚                    â”‚                              â”‚
â”‚                 â”‚  1. Read both      â”‚                              â”‚
â”‚                 â”‚  2. Align schema   â”‚                              â”‚
â”‚                 â”‚  3. Union          â”‚                              â”‚
â”‚                 â”‚  4. Deduplicate    â”‚                              â”‚
â”‚                 â”‚  5. Recompute MA   â”‚                              â”‚
â”‚                 â”‚  6. Save           â”‚                              â”‚
â”‚                 â”‚                    â”‚                              â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                           â”‚                                         â”‚
â”‚                           â–¼                                         â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                 â”‚    MERGED DATA     â”‚                              â”‚
â”‚                 â”‚  daily_filled/     â”‚                              â”‚
â”‚                 â”‚                    â”‚                              â”‚
â”‚                 â”‚  BTCUSDT:          â”‚                              â”‚
â”‚                 â”‚  2012 â†’ 2025-12-03 â”‚                              â”‚
â”‚                 â”‚  ~4710 days        â”‚                              â”‚
â”‚                 â”‚                    â”‚                              â”‚
â”‚                 â”‚  ETHUSDT:          â”‚                              â”‚
â”‚                 â”‚  2017 â†’ 2025-12-03 â”‚                              â”‚
â”‚                 â”‚  ~2910 days        â”‚                              â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                           â”‚                                         â”‚
â”‚                           â–¼                                         â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                 â”‚  prophet_train.py  â”‚                              â”‚
â”‚                 â”‚                    â”‚                              â”‚
â”‚                 â”‚  â€¢ Load data       â”‚                              â”‚
â”‚                 â”‚  â€¢ Train Prophet   â”‚                              â”‚
â”‚                 â”‚  â€¢ Forecast 30d    â”‚                              â”‚
â”‚                 â”‚  â€¢ Visualize       â”‚                              â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                           â”‚                                         â”‚
â”‚                           â–¼                                         â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                 â”‚      OUTPUTS       â”‚                              â”‚
â”‚                 â”‚                    â”‚                              â”‚
â”‚                 â”‚  week4_forecasts/  â”‚                              â”‚
â”‚                 â”‚  week4_metrics/    â”‚                              â”‚
â”‚                 â”‚  week4_results/    â”‚                              â”‚
â”‚                 â”‚  week4_visualizations/â”‚                           â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2. Files trong Serving Layer

```
Project/
â”œâ”€â”€ week6_merge.py       # Merge Batch + Speed Layer
â”œâ”€â”€ prophet_train.py     # Train Prophet, forecast
â”‚
â”œâ”€â”€ data_analysis/
â”‚   â”œâ”€â”€ daily_filled/    # Input/Output cá»§a merge
â”‚   â”‚   â”œâ”€â”€ symbol=BTCUSDT/
â”‚   â”‚   â””â”€â”€ symbol=ETHUSDT/
â”‚   â”‚
â”‚   â”œâ”€â”€ prophet_input/   # Input cho Prophet
â”‚   â”‚   â”œâ”€â”€ symbol=BTCUSDT/
â”‚   â”‚   â””â”€â”€ symbol=ETHUSDT/
â”‚   â”‚
â”‚   â”œâ”€â”€ week4_forecasts/ # Prophet forecasts
â”‚   â”œâ”€â”€ week4_metrics/   # MAPE, RMSE
â”‚   â”œâ”€â”€ week4_results/   # Actual vs Predicted
â”‚   â””â”€â”€ week4_visualizations/ # Charts
â”‚
â””â”€â”€ streaming_output_spark/  # Speed Layer output
    â””â”€â”€ daily/
```

---

## 3. week6_merge.py - Giáº£i thÃ­ch chi tiáº¿t

### 3.1. Tá»•ng quan

```python
"""
week6_merge.py

Nhiá»‡m vá»¥:
1. Äá»c Batch Layer data (daily_filled)
2. Äá»c Speed Layer data (streaming_output_spark/daily)
3. Merge + Deduplicate
4. Recompute MA7/MA30
5. Save unified dataset
"""
```

### 3.2. Step 1: Read Batch Layer

```python
# ============================================================================
# STEP 1: READ BATCH LAYER DATA
# ============================================================================
print("\n[STEP 1] Reading Batch Layer (backfill data)...")

# Äá»c tá»« daily_filled
# ÄÃ¢y lÃ  output cá»§a week6_backfill.py
df_batch = spark.read.parquet("data_analysis/daily_filled")

batch_count = df_batch.count()
print(f"  âœ… Batch data loaded: {batch_count:,} rows")

# Thá»‘ng kÃª
df_batch.groupBy("symbol").agg(
    count("*").alias("days"),        # Sá»‘ ngÃ y
    min("date").alias("first_date"), # NgÃ y Ä‘áº§u
    max("date").alias("last_date")   # NgÃ y cuá»‘i
).show(truncate=False)

# Output:
# +-------+-----+----------+----------+
# |symbol |days |first_date|last_date |
# +-------+-----+----------+----------+
# |BTCUSDT|4711 |2012-01-01|2025-11-23|
# |ETHUSDT|2912 |2017-08-17|2025-11-23|
# +-------+-----+----------+----------+
```

### 3.3. Step 2: Read Speed Layer

```python
# ============================================================================
# STEP 2: READ SPEED LAYER DATA (STREAMING)
# ============================================================================
print("\n[STEP 2] Reading Speed Layer (streaming data)...")

streaming_path = "streaming_output_spark/daily"

# Kiá»ƒm tra folder tá»“n táº¡i
if not os.path.exists(streaming_path):
    print(f"  âš ï¸  No streaming data found at {streaming_path}")
    # HÆ°á»›ng dáº«n user start streaming
    exit(0)

# Äá»c streaming data
df_streaming = spark.read.parquet(streaming_path)

streaming_count = df_streaming.count()
print(f"  âœ… Streaming data loaded: {streaming_count:,} rows")

# Output:
# +-------+-----+----------+----------+
# |symbol |days |first_date|last_date |
# +-------+-----+----------+----------+
# |BTCUSDT|10   |2025-11-24|2025-12-03|
# |ETHUSDT|10   |2025-11-24|2025-12-03|
# +-------+-----+----------+----------+
```

### 3.4. Step 3: Align Schema vÃ  Merge

```python
# ============================================================================
# STEP 3: ALIGN SCHEMAS AND MERGE
# ============================================================================
print("\n[STEP 3] Merging batch + streaming data...")

# Batch columns vs Streaming columns
batch_cols = set(df_batch.columns)
# {'symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'MA7', 'MA30', 'year'}

streaming_cols = set(df_streaming.columns)
# {'symbol', 'date', 'daily_open', 'daily_high', 'daily_low', 'daily_close', 
#  'daily_volume', 'window'}

# Common columns (rename náº¿u cáº§n)
common_cols = ["symbol", "date", "open", "high", "low", "close", "volume"]

# Align batch
df_batch_aligned = df_batch.select(*common_cols)

# Align streaming (rename daily_* â†’ *)
df_streaming_aligned = df_streaming.select(
    col("symbol"),
    col("date"),
    col("daily_open").alias("open"),
    col("daily_high").alias("high"),
    col("daily_low").alias("low"),
    col("daily_close").alias("close"),
    col("daily_volume").alias("volume")
)

# Add null MA7/MA30 cho streaming (sáº½ tÃ­nh láº¡i sau)
from pyspark.sql.functions import lit
df_streaming_aligned = df_streaming_aligned \
    .withColumn("MA7", lit(None).cast("double")) \
    .withColumn("MA30", lit(None).cast("double"))

# UNION: Gá»™p 2 DataFrames
df_merged = df_batch_aligned.union(df_streaming_aligned)

# DEDUPLICATE: Loáº¡i bá» trÃ¹ng láº·p
# Giá»¯ 1 row cho má»—i (symbol, date)
df_merged = df_merged.dropDuplicates(["symbol", "date"])

# SORT: Sáº¯p xáº¿p theo symbol, date
df_merged = df_merged.orderBy("symbol", "date")

merged_count = df_merged.count()
print(f"  âœ… Merged data: {merged_count:,} rows")
```

### 3.5. Minh há»a Union vÃ  Deduplicate

```
UNION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  BATCH (4711 rows):                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ BTCUSDT | 2012-01-01 | open | high | low | close   â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2012-01-02 | ...                         â”‚            â”‚
â”‚  â”‚ ...                                                 â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-11-23 | ...                         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                     â”‚
â”‚  STREAMING (10 rows):                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ BTCUSDT | 2025-11-23 | open | high | low | close   â”‚ â† TRÃ™NG!  â”‚
â”‚  â”‚ BTCUSDT | 2025-11-24 | ...                         â”‚            â”‚
â”‚  â”‚ ...                                                 â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-12-03 | ...                         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                     â”‚
â”‚  AFTER UNION (4721 rows):                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ BTCUSDT | 2012-01-01 | ...                         â”‚            â”‚
â”‚  â”‚ ...                                                 â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-11-23 | ... (from batch)            â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-11-23 | ... (from streaming) â† TRÃ™NG!â”‚           â”‚
â”‚  â”‚ BTCUSDT | 2025-11-24 | ...                         â”‚            â”‚
â”‚  â”‚ ...                                                 â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-12-03 | ...                         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DEDUPLICATE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  dropDuplicates(["symbol", "date"])                                â”‚
â”‚                                                                     â”‚
â”‚  BEFORE: 4721 rows (cÃ³ trÃ¹ng 2025-11-23)                          â”‚
â”‚  AFTER:  4720 rows (khÃ´ng trÃ¹ng)                                   â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ BTCUSDT | 2012-01-01 | ...                         â”‚            â”‚
â”‚  â”‚ ...                                                 â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-11-23 | ... (giá»¯ 1 báº£n)             â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-11-24 | ...                         â”‚            â”‚
â”‚  â”‚ ...                                                 â”‚            â”‚
â”‚  â”‚ BTCUSDT | 2025-12-03 | ...                         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.6. Step 4: Recompute MA7/MA30

```python
# ============================================================================
# STEP 4: RECOMPUTE MA7/MA30 FOR ENTIRE TIMELINE
# ============================================================================
print("\n[STEP 4] Recomputing MA7/MA30 for merged timeline...")

# Window function cho MA7
# Láº¥y trung bÃ¬nh 7 ngÃ y gáº§n nháº¥t (bao gá»“m ngÃ y hiá»‡n táº¡i)
window_ma7 = Window \
    .partitionBy("symbol")     # TÃ­nh riÃªng cho má»—i symbol
    .orderBy("date")           # Sáº¯p xáº¿p theo ngÃ y
    .rowsBetween(-6, 0)        # 6 ngÃ y trÆ°á»›c + ngÃ y hiá»‡n táº¡i = 7 ngÃ y

# Window function cho MA30
window_ma30 = Window \
    .partitionBy("symbol") \
    .orderBy("date") \
    .rowsBetween(-29, 0)       # 29 ngÃ y trÆ°á»›c + ngÃ y hiá»‡n táº¡i = 30 ngÃ y

# Compute MA
df_merged = df_merged.withColumn("MA7", avg("close").over(window_ma7))
df_merged = df_merged.withColumn("MA30", avg("close").over(window_ma30))

print(f"  âœ… MA7 and MA30 recomputed")
```

### 3.7. Táº¡i sao pháº£i tÃ­nh láº¡i MA?

```
Váº¥n Ä‘á»: MA7/MA30 cáº§n timeline liÃªn tá»¥c

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  TrÆ°á»›c merge:                                                       â”‚
â”‚                                                                     â”‚
â”‚  BATCH: [..., 11/21, 11/22, 11/23] â† MA30 tÃ­nh Ä‘áº¿n 11/23           â”‚
â”‚                                                                     â”‚
â”‚  STREAMING: [11/24, 11/25, ..., 12/03] â† MA30 = NULL               â”‚
â”‚             (chá»‰ cÃ³ 10 ngÃ y, khÃ´ng Ä‘á»§ 30 ngÃ y Ä‘á»ƒ tÃ­nh MA30)        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Sau merge + recompute:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  MERGED: [..., 11/21, 11/22, 11/23, 11/24, 11/25, ..., 12/03]     â”‚
â”‚                                                                     â”‚
â”‚  MA30 cho ngÃ y 12/03:                                              â”‚
â”‚  = avg(close cá»§a 30 ngÃ y: 11/04 â†’ 12/03)                           â”‚
â”‚  = GiÃ¡ trá»‹ chÃ­nh xÃ¡c âœ“                                             â”‚
â”‚                                                                     â”‚
â”‚  KhÃ´ng cÃ³ gaps, timeline liÃªn tá»¥c                                  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.8. Step 5: Save Unified Dataset

```python
# ============================================================================
# STEP 5: SAVE UNIFIED DATASET
# ============================================================================
print("\n[STEP 5] Saving unified dataset...")

# Add year column cho partitioning
df_merged = df_merged.withColumn("year", year("date"))

# Save vá»›i partitioning
output_path = "data_analysis/daily_filled"
df_merged.write \
    .mode("overwrite") \         # Ghi Ä‘Ã¨ data cÅ©
    .partitionBy("symbol", "year") \
    .parquet(output_path)

print(f"  âœ… Saved to {output_path}")

# Update prophet_input (format cho Prophet)
df_prophet = df_merged.select(
    col("date").alias("ds"),     # Prophet cáº§n cá»™t "ds"
    col("close").alias("y"),     # Prophet cáº§n cá»™t "y"
    "symbol",
    "MA7",
    "MA30"
).orderBy("symbol", "ds")

df_prophet.write \
    .mode("overwrite") \
    .partitionBy("symbol") \
    .parquet("data_analysis/prophet_input")

print(f"  âœ… Prophet input updated")
```

---

## 4. prophet_train.py - Giáº£i thÃ­ch chi tiáº¿t

### 4.1. Prophet lÃ  gÃ¬?

```
Facebook Prophet lÃ  time series forecasting library:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PROPHET MODEL                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  y(t) = g(t) + s(t) + h(t) + Îµ(t)                                 â”‚
â”‚                                                                     â”‚
â”‚  g(t) = TREND component                                            â”‚
â”‚         â””â”€â”€ Linear hoáº·c Logistic growth                            â”‚
â”‚         â””â”€â”€ Changepoints (Ä‘iá»ƒm thay Ä‘á»•i trend)                    â”‚
â”‚                                                                     â”‚
â”‚  s(t) = SEASONALITY component                                      â”‚
â”‚         â””â”€â”€ Yearly seasonality                                     â”‚
â”‚         â””â”€â”€ Weekly seasonality                                     â”‚
â”‚         â””â”€â”€ Custom seasonality                                     â”‚
â”‚                                                                     â”‚
â”‚  h(t) = HOLIDAY effects                                            â”‚
â”‚         â””â”€â”€ Events Ä‘áº·c biá»‡t                                        â”‚
â”‚                                                                     â”‚
â”‚  Îµ(t) = ERROR (noise)                                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Æ¯u Ä‘iá»ƒm:
âœ… Dá»… sá»­ dá»¥ng (chá»‰ cáº§n df vá»›i "ds" vÃ  "y")
âœ… Xá»­ lÃ½ missing data tá»‘t
âœ… Robust vá»›i outliers
âœ… Tá»± Ä‘á»™ng detect changepoints
âœ… Interpretable (giáº£i thÃ­ch Ä‘Æ°á»£c)
```

### 4.2. Tá»•ng quan prophet_train.py

```python
"""
prophet_train.py

Flow:
1. Load data tá»« prophet_input
2. Train Prophet model cho má»—i symbol
3. Forecast 30 ngÃ y tÆ°Æ¡ng lai
4. Evaluate vá»›i MAPE, RMSE
5. Visualize vá»›i Plotly
6. Save káº¿t quáº£
"""
```

### 4.3. Load Data

```python
# Load data
spark = SparkSession.builder \
    .appName("ProphetTraining") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

df = spark.read.parquet("data_analysis/prophet_input")

# Filter by symbol
df_btc = df.filter(col("symbol") == "BTCUSDT").toPandas()
df_eth = df.filter(col("symbol") == "ETHUSDT").toPandas()

# Prophet cáº§n DataFrame vá»›i columns: ds, y
# ds = date, y = value to predict (close price)
print(f"BTC: {len(df_btc)} days")
print(f"ETH: {len(df_eth)} days")
```

### 4.4. Train Prophet

```python
def train_and_forecast(df, symbol, periods=30):
    """
    Train Prophet vÃ  forecast
    
    Parameters:
    - df: DataFrame vá»›i columns (ds, y)
    - symbol: "BTCUSDT" hoáº·c "ETHUSDT"
    - periods: Sá»‘ ngÃ y forecast (default 30)
    """
    
    # ============================================
    # TRAIN PROPHET
    # ============================================
    model = Prophet(
        # SEASONALITY
        yearly_seasonality=True,    # CÃ³ yearly pattern
        weekly_seasonality=True,    # CÃ³ weekly pattern
        daily_seasonality=False,    # KhÃ´ng daily (data lÃ  daily)
        
        # CHANGEPOINTS
        changepoint_prior_scale=0.05,  # Flexibility cá»§a trend
        # 0.5 = ráº¥t flexible (cÃ³ thá»ƒ overfit)
        # 0.001 = ráº¥t rigid (cÃ³ thá»ƒ underfit)
        
        # SEASONALITY STRENGTH
        seasonality_prior_scale=10,
        
        # UNCERTAINTY
        interval_width=0.95  # 95% confidence interval
    )
    
    # Fit model (huáº¥n luyá»‡n)
    model.fit(df)
    
    # ============================================
    # FORECAST
    # ============================================
    # Táº¡o DataFrame cho future dates
    future = model.make_future_dataframe(periods=periods)
    
    # Forecast
    forecast = model.predict(future)
    
    # forecast DataFrame cÃ³ nhiá»u columns:
    # - ds: date
    # - yhat: predicted value
    # - yhat_lower: lower bound (95% CI)
    # - yhat_upper: upper bound (95% CI)
    # - trend: trend component
    # - yearly: yearly seasonality
    # - weekly: weekly seasonality
    
    return model, forecast
```

### 4.5. Evaluate Model

```python
def evaluate_model(actual, predicted):
    """
    TÃ­nh metrics Ä‘Ã¡nh giÃ¡ model
    
    MAPE = Mean Absolute Percentage Error
    RMSE = Root Mean Square Error
    MAE = Mean Absolute Error
    """
    
    # ============================================
    # MAPE (Mean Absolute Percentage Error)
    # ============================================
    # MAPE = (1/n) * Î£ |actual - predicted| / |actual| * 100%
    #
    # Ã nghÄ©a:
    # - MAPE 5% nghÄ©a lÃ  trung bÃ¬nh sai 5% so vá»›i actual
    # - CÃ ng tháº¥p cÃ ng tá»‘t
    # - < 10% = tá»‘t, < 20% = cháº¥p nháº­n Ä‘Æ°á»£c
    
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    
    # ============================================
    # RMSE (Root Mean Square Error)
    # ============================================
    # RMSE = sqrt((1/n) * Î£ (actual - predicted)Â²)
    #
    # Ã nghÄ©a:
    # - RMSE = $1000 nghÄ©a lÃ  error trung bÃ¬nh ~$1000
    # - Penalize large errors nhiá»u hÆ¡n
    
    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
    
    # ============================================
    # MAE (Mean Absolute Error)
    # ============================================
    # MAE = (1/n) * Î£ |actual - predicted|
    
    mae = np.mean(np.abs(actual - predicted))
    
    return {"MAPE": mape, "RMSE": rmse, "MAE": mae}

# Trong project, káº¿t quáº£:
# BTC: MAPE â‰ˆ 4.5%, RMSE â‰ˆ $4000
# ETH: MAPE â‰ˆ 4.5%, RMSE â‰ˆ $150
```

### 4.6. Visualization

```python
def create_visualization(model, forecast, df, symbol):
    """
    Táº¡o interactive chart vá»›i Plotly
    """
    
    import plotly.graph_objects as go
    
    fig = go.Figure()
    
    # ============================================
    # ACTUAL DATA (Ä‘Æ°á»ng xanh)
    # ============================================
    fig.add_trace(go.Scatter(
        x=df['ds'],
        y=df['y'],
        mode='lines',
        name='Actual',
        line=dict(color='blue', width=1)
    ))
    
    # ============================================
    # FORECAST (Ä‘Æ°á»ng Ä‘á»)
    # ============================================
    fig.add_trace(go.Scatter(
        x=forecast['ds'],
        y=forecast['yhat'],
        mode='lines',
        name='Forecast',
        line=dict(color='red', width=2)
    ))
    
    # ============================================
    # CONFIDENCE INTERVAL (vÃ¹ng xÃ¡m)
    # ============================================
    fig.add_trace(go.Scatter(
        x=forecast['ds'].tolist() + forecast['ds'].tolist()[::-1],
        y=forecast['yhat_upper'].tolist() + forecast['yhat_lower'].tolist()[::-1],
        fill='toself',
        fillcolor='rgba(128,128,128,0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        name='95% Confidence Interval'
    ))
    
    # ============================================
    # LAYOUT
    # ============================================
    fig.update_layout(
        title=f'{symbol} Price Forecast',
        xaxis_title='Date',
        yaxis_title='Price (USD)',
        hovermode='x unified',
        showlegend=True
    )
    
    # Save as HTML (interactive)
    fig.write_html(f"week4_visualizations/{symbol}_forecast_interactive.html")
```

### 4.7. Output Files

```
Sau khi cháº¡y prophet_train.py:

data_analysis/
â”œâ”€â”€ week4_forecasts/
â”‚   â”œâ”€â”€ BTCUSDT_forecast.parquet
â”‚   â””â”€â”€ ETHUSDT_forecast.parquet
â”‚
â”œâ”€â”€ week4_metrics/
â”‚   â””â”€â”€ metrics.csv
â”‚   # symbol,MAPE,RMSE,MAE
â”‚   # BTCUSDT,4.52,4123.45,3567.89
â”‚   # ETHUSDT,4.61,156.78,134.56
â”‚
â”œâ”€â”€ week4_results/
â”‚   â”œâ”€â”€ BTCUSDT_actual_vs_pred.csv
â”‚   â””â”€â”€ ETHUSDT_actual_vs_pred.csv
â”‚   # date,actual,predicted,error,error_percent
â”‚
â””â”€â”€ week4_visualizations/
    â”œâ”€â”€ BTCUSDT_forecast_interactive.html
    â””â”€â”€ ETHUSDT_forecast_interactive.html
```

---

## 5. Káº¿t ná»‘i 3 Layers

### 5.1. Full Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLETE LAMBDA ARCHITECTURE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    DATA SOURCE                              â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  Binance API: https://api.binance.com/api/v3/              â”‚    â”‚
â”‚  â”‚  â”œâ”€â”€ /klines (historical OHLCV)                            â”‚    â”‚
â”‚  â”‚  â””â”€â”€ /ticker/24hr (real-time price)                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                               â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚              â”‚                                 â”‚                   â”‚
â”‚              â–¼                                 â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   BATCH LAYER    â”‚              â”‚   SPEED LAYER    â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚                  â”‚           â”‚
â”‚  â”‚ week6_backfill.pyâ”‚              â”‚ websocket_       â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚ producer.py      â”‚           â”‚
â”‚  â”‚ â€¢ Detect gap     â”‚              â”‚ â€¢ Poll API 1s    â”‚           â”‚
â”‚  â”‚ â€¢ Fetch klines   â”‚              â”‚ â€¢ Send to Kafka  â”‚           â”‚
â”‚  â”‚ â€¢ Daily agg      â”‚              â”‚                  â”‚           â”‚
â”‚  â”‚ â€¢ MA7/MA30       â”‚              â”‚ spark_streaming_ â”‚           â”‚
â”‚  â”‚ â€¢ Forward fill   â”‚              â”‚ consumer.py      â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚ â€¢ Read Kafka     â”‚           â”‚
â”‚  â”‚ Output:          â”‚              â”‚ â€¢ Window agg     â”‚           â”‚
â”‚  â”‚ daily_filled/    â”‚              â”‚ â€¢ Watermark      â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚                  â”‚           â”‚
â”‚  â”‚ 2012 â†’ 2025-11   â”‚              â”‚ Output:          â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚ streaming_output_â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚ spark/daily/     â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚                  â”‚           â”‚
â”‚  â”‚                  â”‚              â”‚ 2025-11 â†’ now    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â”‚                                 â”‚                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                           â”‚                                        â”‚
â”‚                           â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     SERVING LAYER                          â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  week6_merge.py                                           â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Read Batch data                                      â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Read Speed data                                      â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Union + Deduplicate                                  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Recompute MA7/MA30                                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Save unified dataset                                 â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  prophet_train.py                                         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Load merged data                                     â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Train Prophet model                                  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Forecast 30 days                                     â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Evaluate (MAPE, RMSE)                               â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Visualize (Plotly HTML)                             â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  Output:                                                   â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ daily_filled/ (unified)                              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ prophet_input/                                       â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ week4_forecasts/                                     â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ week4_metrics/                                       â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ week4_results/                                       â”‚   â”‚
â”‚  â”‚  â””â”€â”€ week4_visualizations/                                â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                        â”‚
â”‚                           â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      END USER                              â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â”‚  â€¢ View forecasts                                         â”‚   â”‚
â”‚  â”‚  â€¢ Analyze trends                                         â”‚   â”‚
â”‚  â”‚  â€¢ Make decisions                                         â”‚   â”‚
â”‚  â”‚                                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2. Thá»© tá»± cháº¡y

```
STEP 1: Start Docker (Kafka)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cd week6_streaming                                                  â”‚
â”‚ docker-compose up -d                                                â”‚
â”‚ # Wait 15 seconds                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 2: Run Backfill (Batch Layer)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ python week6_backfill.py                                           â”‚
â”‚ # Fills gap from last data to today                                â”‚
â”‚ # Output: data_analysis/daily_filled/                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 3: Start Producer (Terminal 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cd week6_streaming                                                  â”‚
â”‚ python websocket_producer.py                                        â”‚
â”‚ # Sends data to Kafka every second                                 â”‚
â”‚ # Let it run for 60+ seconds                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 4: Start Consumer (Terminal 2)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cd week6_streaming                                                  â”‚
â”‚ python spark_streaming_consumer.py                                  â”‚
â”‚ # Reads from Kafka, aggregates, saves to Parquet                   â”‚
â”‚ # Let it run for 60+ seconds                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 5: Stop Producer & Consumer
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ctrl+C in both terminals                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 6: Merge (Serving Layer)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ python week6_merge.py                                              â”‚
â”‚ # Merges Batch + Speed data                                        â”‚
â”‚ # Output: unified daily_filled/                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 7: Forecast (Serving Layer)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ python prophet_train.py                                            â”‚
â”‚ # Trains Prophet, forecasts 30 days                                â”‚
â”‚ # Output: week4_forecasts/, week4_visualizations/                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 8: Cleanup
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cd week6_streaming                                                  â”‚
â”‚ docker-compose down -v                                              â”‚
â”‚ # Stop and remove Docker containers                                â”‚
â”‚                                                                     â”‚
â”‚ Remove-Item -Recurse -Force checkpoint_spark                       â”‚
â”‚ Remove-Item -Recurse -Force streaming_output_spark                 â”‚
â”‚ # Clean up streaming artifacts                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Output vÃ  Káº¿t quáº£

### 6.1. Forecast Results

```
Káº¿t quáº£ forecast ngÃ y 03/12/2025:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  BTCUSDT:                                                          â”‚
â”‚  â”œâ”€â”€ Current Price: $92,817.92                                     â”‚
â”‚  â”œâ”€â”€ 30-day Forecast: $95,000 - $100,000 (trend up)               â”‚
â”‚  â”œâ”€â”€ MAPE: 4.52%                                                   â”‚
â”‚  â””â”€â”€ Interpretation: Model khÃ¡ chÃ­nh xÃ¡c                          â”‚
â”‚                                                                     â”‚
â”‚  ETHUSDT:                                                          â”‚
â”‚  â”œâ”€â”€ Current Price: $3,031.32                                      â”‚
â”‚  â”œâ”€â”€ 30-day Forecast: $3,100 - $3,500 (trend up)                  â”‚
â”‚  â”œâ”€â”€ MAPE: 4.61%                                                   â”‚
â”‚  â””â”€â”€ Interpretation: Model khÃ¡ chÃ­nh xÃ¡c                          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LÆ°u Ã½:
- MAPE < 10% = Model tá»‘t
- Crypto volatile nÃªn MAPE 4-5% lÃ  ráº¥t tá»‘t
- Forecast chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng pháº£i financial advice
```

### 6.2. Visualization

```
File: week4_visualizations/BTCUSDT_forecast_interactive.html

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Interactive Chart]                                               â”‚
â”‚                                                                     â”‚
â”‚  Price                                                              â”‚
â”‚  $100k â”‚                                          â”Œâ”€â”€â”€ Forecast    â”‚
â”‚        â”‚                                      â•±â”€â”€â”€â”˜    (red)       â”‚
â”‚   $90k â”‚                                 â•±â”€â”€â”€â”€â•±                    â”‚
â”‚        â”‚                            â•±â”€â”€â”€â”€â•±                         â”‚
â”‚   $80k â”‚                       â•±â”€â”€â”€â”€â•±                              â”‚
â”‚        â”‚                  â•±â”€â”€â”€â”€â•±                                   â”‚
â”‚   $70k â”‚             â•±â”€â”€â”€â”€â•±                                        â”‚
â”‚        â”‚        â•±â”€â”€â”€â”€â•±                                             â”‚
â”‚   $60k â”‚   â•±â”€â”€â”€â”€â•±   Actual (blue)                                  â”‚
â”‚        â”‚â•±â”€â”€â•±                                                       â”‚
â”‚   $50k â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚        2024-01    2024-06    2024-12    2025-06    2025-12         â”‚
â”‚                                                                     â”‚
â”‚  [Hover Ä‘á»ƒ xem giÃ¡ chi tiáº¿t]                                       â”‚
â”‚  [Zoom in/out vá»›i scroll]                                          â”‚
â”‚  [Pan vá»›i drag]                                                    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. CÃ¢u há»i thÆ°á»ng gáº·p

### Q1: Táº¡i sao dÃ¹ng MAPE thay vÃ¬ accuracy?

```
A: MAPE phÃ¹ há»£p hÆ¡n cho time series regression:

Accuracy dÃ¹ng cho classification:
- ÄÃºng/Sai
- VÃ­ dá»¥: 95% predictions Ä‘Ãºng

MAPE dÃ¹ng cho regression:
- Äo % sai lá»‡ch
- VÃ­ dá»¥: Trung bÃ¬nh sai 5% so vá»›i actual

Trong crypto:
- Actual = $92,000
- Predicted = $88,000
- Error = $4,000
- MAPE = 4.3%

â†’ MAPE cho biáº¿t model sai trung bÃ¬nh bao nhiÃªu %
```

### Q2: Prophet cÃ³ thá»ƒ forecast bao xa?

```
A: Vá» máº·t ká»¹ thuáº­t, bao xa cÅ©ng Ä‘Æ°á»£c. NhÆ°ng:

Ngáº¯n háº¡n (1-7 ngÃ y):
â”œâ”€â”€ Äá»™ chÃ­nh xÃ¡c cao
â”œâ”€â”€ Trend á»•n Ä‘á»‹nh
â””â”€â”€ Recommended

Trung háº¡n (7-30 ngÃ y):
â”œâ”€â”€ Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh
â”œâ”€â”€ Trend cÃ³ thá»ƒ thay Ä‘á»•i
â””â”€â”€ Cáº§n cáº©n tháº­n

DÃ i háº¡n (30+ ngÃ y):
â”œâ”€â”€ Äá»™ chÃ­nh xÃ¡c tháº¥p
â”œâ”€â”€ Nhiá»u yáº¿u tá»‘ khÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£c
â””â”€â”€ Chá»‰ mang tÃ­nh tham kháº£o

Trong project:
- Forecast 30 ngÃ y lÃ  reasonable
- Crypto volatile nÃªn khÃ´ng nÃªn forecast quÃ¡ xa
```

### Q3: Serving Layer cÃ³ thá»ƒ query real-time khÃ´ng?

```
A: CÃ³, nhÆ°ng cáº§n thiáº¿t láº­p:

Hiá»‡n táº¡i (Batch serving):
â”œâ”€â”€ Cháº¡y merge.py + prophet_train.py
â”œâ”€â”€ Káº¿t quáº£ lÆ°u vÃ o files
â”œâ”€â”€ KhÃ´ng real-time

Real-time serving (cáº£i tiáº¿n):
â”œâ”€â”€ Memory table trong Spark
â”œâ”€â”€ REST API (Flask/FastAPI)
â”œâ”€â”€ Dashboard (Streamlit/Dash)
â”œâ”€â”€ Query báº¥t cá»© lÃºc nÃ o

VÃ­ dá»¥ vá»›i Streamlit:
import streamlit as st

df = pd.read_parquet("week4_forecasts/BTCUSDT_forecast.parquet")
st.line_chart(df[['ds', 'yhat']])
```

### Q4: Merge cÃ³ máº¥t data khÃ´ng?

```
A: KhÃ´ng, merge Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giá»¯ toÃ n bá»™ data:

1. UNION: Gá»™p táº¥t cáº£ rows tá»« cáº£ 2 sources
   KhÃ´ng máº¥t row nÃ o

2. DEDUPLICATE: Chá»‰ loáº¡i duplicates
   Náº¿u (symbol, date) trÃ¹ng â†’ giá»¯ 1 báº£n
   ÄÃ¢y lÃ  expected behavior

3. Verify:
   Batch: 4711 rows
   Streaming: 10 rows (cÃ³ 1 ngÃ y overlap)
   After merge: 4720 rows = 4711 + 10 - 1 âœ“
```

---

## 8. Tá»•ng káº¿t Week 6

### 8.1. Nhá»¯ng gÃ¬ Ä‘Ã£ há»c

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WEEK 6 - LAMBDA ARCHITECTURE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. BATCH LAYER                                                     â”‚
â”‚     â”œâ”€â”€ Xá»­ lÃ½ dá»¯ liá»‡u lá»‹ch sá»­ lá»›n                                  â”‚
â”‚     â”œâ”€â”€ PySpark distributed processing                             â”‚
â”‚     â”œâ”€â”€ Binance API (klines endpoint)                              â”‚
â”‚     â”œâ”€â”€ Forward fill missing days                                  â”‚
â”‚     â””â”€â”€ MA7/MA30 computation                                       â”‚
â”‚                                                                     â”‚
â”‚  2. SPEED LAYER                                                     â”‚
â”‚     â”œâ”€â”€ Apache Kafka message broker                                â”‚
â”‚     â”œâ”€â”€ Docker containerization                                    â”‚
â”‚     â”œâ”€â”€ Kafka Producer (Python)                                    â”‚
â”‚     â”œâ”€â”€ Spark Structured Streaming                                 â”‚
â”‚     â”œâ”€â”€ Watermark (late data handling)                            â”‚
â”‚     â””â”€â”€ Window aggregation                                         â”‚
â”‚                                                                     â”‚
â”‚  3. SERVING LAYER                                                   â”‚
â”‚     â”œâ”€â”€ Data merging (Union + Deduplicate)                        â”‚
â”‚     â”œâ”€â”€ Schema alignment                                           â”‚
â”‚     â”œâ”€â”€ Facebook Prophet forecasting                               â”‚
â”‚     â”œâ”€â”€ Model evaluation (MAPE, RMSE)                             â”‚
â”‚     â””â”€â”€ Interactive visualization (Plotly)                         â”‚
â”‚                                                                     â”‚
â”‚  4. TECHNOLOGIES                                                    â”‚
â”‚     â”œâ”€â”€ PySpark 3.5.3                                              â”‚
â”‚     â”œâ”€â”€ Apache Kafka 7.5.0 (via Docker)                            â”‚
â”‚     â”œâ”€â”€ Facebook Prophet 1.1.5                                     â”‚
â”‚     â”œâ”€â”€ Plotly (visualization)                                     â”‚
â”‚     â””â”€â”€ Docker Compose                                             â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2. Key Takeaways

```
1. LAMBDA ARCHITECTURE giáº£i quyáº¿t tradeoff:
   - Batch: ChÃ­nh xÃ¡c nhÆ°ng cháº­m
   - Speed: Nhanh nhÆ°ng cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c
   - Serving: Káº¿t há»£p cáº£ hai

2. KAFKA lÃ  message broker:
   - Decoupling producer/consumer
   - Durability (khÃ´ng máº¥t data)
   - Scalability (nhiá»u consumers)

3. SPARK STRUCTURED STREAMING:
   - DataFrame/SQL API cho streaming
   - Watermark xá»­ lÃ½ late data
   - Window aggregation

4. PROPHET:
   - Dá»… sá»­ dá»¥ng cho time series
   - Tá»± Ä‘á»™ng detect trend/seasonality
   - Interpretable results
```

### 8.3. Äiá»ƒm cáº§n trÃ¬nh bÃ y vá»›i giÃ¡o sÆ°

```
1. ARCHITECTURE:
   "Em Ä‘Ã£ implement Lambda Architecture vá»›i 3 layers:
   Batch Layer cho historical data, Speed Layer cho real-time,
   vÃ  Serving Layer Ä‘á»ƒ merge vÃ  serve káº¿t quáº£."

2. TECHNOLOGIES:
   "Em sá»­ dá»¥ng PySpark cho distributed processing,
   Apache Kafka cho message streaming,
   vÃ  Facebook Prophet cho time series forecasting."

3. RESULTS:
   "Model Prophet Ä‘áº¡t MAPE khoáº£ng 4.5%,
   nghÄ©a lÃ  trung bÃ¬nh sai khoáº£ng 4.5% so vá»›i giÃ¡ thá»±c.
   ÄÃ¢y lÃ  káº¿t quáº£ tá»‘t cho volatile asset nhÆ° crypto."

4. CHALLENGES:
   "KhÃ³ khÄƒn chÃ­nh lÃ :
   - Setup Kafka vá»›i Docker trÃªn Windows
   - Handle late data vá»›i watermark
   - Align schema giá»¯a batch vÃ  streaming data"

5. IMPROVEMENTS:
   "CÃ³ thá»ƒ cáº£i tiáº¿n báº±ng cÃ¡ch:
   - ThÃªm real-time dashboard
   - Sá»­ dá»¥ng multiple models (ensemble)
   - Add more features (sentiment analysis, etc.)"
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

1. **Lambda Architecture:**
   - Nathan Marz - "Big Data: Principles and best practices"
   - https://lambda-architecture.net/

2. **Apache Kafka:**
   - https://kafka.apache.org/documentation/
   - Confluent Documentation

3. **Spark Structured Streaming:**
   - https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html

4. **Facebook Prophet:**
   - https://facebook.github.io/prophet/
   - https://facebook.github.io/prophet/docs/quick_start.html

---

*Táº¡o bá»Ÿi: Big Data Project - Week 6 Documentation*
*Cáº­p nháº­t: 03/12/2025*
*PhiÃªn báº£n: Complete (4/4 files)*

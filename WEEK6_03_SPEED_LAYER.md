# ğŸ“˜ WEEK 6 - PHáº¦N 3: SPEED LAYER (Kafka + Spark Streaming)

## ğŸ“‘ Má»¥c lá»¥c
1. [Má»¥c Ä‘Ã­ch cá»§a Speed Layer](#1-má»¥c-Ä‘Ã­ch-cá»§a-speed-layer)
2. [Kiáº¿n trÃºc Speed Layer](#2-kiáº¿n-trÃºc-speed-layer)
3. [Apache Kafka - Giáº£i thÃ­ch chi tiáº¿t](#3-apache-kafka---giáº£i-thÃ­ch-chi-tiáº¿t)
4. [Docker vÃ  docker-compose.yml](#4-docker-vÃ -docker-composeyml)
5. [Producer - websocket_producer.py](#5-producer---websocket_producerpy)
6. [Consumer - spark_streaming_consumer.py](#6-consumer---spark_streaming_consumerpy)
7. [Watermark vÃ  Window](#7-watermark-vÃ -window)
8. [Output vÃ  Checkpoint](#8-output-vÃ -checkpoint)
9. [CÃ¢u há»i thÆ°á»ng gáº·p](#9-cÃ¢u-há»i-thÆ°á»ng-gáº·p)

---

## 1. Má»¥c Ä‘Ã­ch cá»§a Speed Layer

### 1.1. Vai trÃ² trong Lambda Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAMBDA ARCHITECTURE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   BATCH LAYER              SPEED LAYER              SERVING LAYER  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Xá»­ lÃ½   â”‚              â”‚ Xá»­ lÃ½   â”‚              â”‚ Merge   â”‚    â”‚
â”‚   â”‚ Lá»ŠCH Sá»¬ â”‚              â”‚REAL-TIMEâ”‚              â”‚ káº¿t quáº£ â”‚    â”‚
â”‚   â”‚         â”‚              â”‚         â”‚              â”‚         â”‚    â”‚
â”‚   â”‚ ChÃ­nh   â”‚              â”‚ Nhanh   â”‚              â”‚ Phá»¥c vá»¥ â”‚    â”‚
â”‚   â”‚ xÃ¡c     â”‚              â”‚         â”‚              â”‚ query   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                 â”‚                                   â”‚
â”‚                                 â”‚                                   â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                          â”‚   ÄÃ‚Y LÃ€    â”‚                           â”‚
â”‚                          â”‚ SPEED LAYER â”‚                           â”‚
â”‚                          â”‚ (Kafka +    â”‚                           â”‚
â”‚                          â”‚  Spark)     â”‚                           â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2. Äáº·c Ä‘iá»ƒm cá»§a Speed Layer

```
Speed Layer chá»‹u trÃ¡ch nhiá»‡m:

1. THU THáº¬P dá»¯ liá»‡u real-time
   â””â”€â”€ Poll Binance API má»—i giÃ¢y

2. TRUYá»€N Táº¢I qua message broker
   â””â”€â”€ Kafka: Äáº£m báº£o khÃ´ng máº¥t data

3. Xá»¬ LÃ vá»›i streaming engine
   â””â”€â”€ Spark Structured Streaming

4. AGGREGATION theo thá»i gian
   â””â”€â”€ Daily windows

5. LÆ¯U TRá»® káº¿t quáº£
   â””â”€â”€ Parquet files
```

### 1.3. Táº¡i sao cáº§n Speed Layer?

```
Váº¥n Ä‘á»: Batch Layer xá»­ lÃ½ cháº­m, khÃ´ng real-time

VÃ­ dá»¥:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚  09:00 - Batch Layer cháº¡y xong, data Ä‘áº¿n 08:59                    â”‚
â”‚  09:01 - BTC tÄƒng $1000 â† Batch Layer khÃ´ng biáº¿t!                 â”‚
â”‚  09:02 - BTC tÄƒng thÃªm $500 â† Batch Layer váº«n khÃ´ng biáº¿t!         â”‚
â”‚  ...                                                               â”‚
â”‚  10:00 - Batch Layer cháº¡y láº¡i, má»›i tháº¥y BTC Ä‘Ã£ tÄƒng $2000         â”‚
â”‚                                                                    â”‚
â”‚  â†’ Cháº­m 1 tiáº¿ng! Trong trading, 1 tiáº¿ng = ráº¥t nguy hiá»ƒm          â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Giáº£i phÃ¡p: Speed Layer bá»• sung dá»¯ liá»‡u real-time

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚  09:00 - Speed Layer: BTC = $92,000                               â”‚
â”‚  09:01 - Speed Layer: BTC = $93,000 (+$1,000) âœ“                   â”‚
â”‚  09:02 - Speed Layer: BTC = $93,500 (+$500)   âœ“                   â”‚
â”‚  ...                                                               â”‚
â”‚  09:59 - Speed Layer: BTC = $94,000                               â”‚
â”‚                                                                    â”‚
â”‚  â†’ Real-time! LuÃ´n cÃ³ dá»¯ liá»‡u má»›i nháº¥t                            â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Kiáº¿n trÃºc Speed Layer

### 2.1. CÃ¡c thÃ nh pháº§n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       SPEED LAYER ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚   BINANCE API    â”‚                          â”‚
â”‚                      â”‚  api.binance.com â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                               â”‚                                     â”‚
â”‚                               â”‚ HTTP GET (1 req/sec)                â”‚
â”‚                               â–¼                                     â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚    PRODUCER      â”‚                          â”‚
â”‚                      â”‚ websocket_       â”‚                          â”‚
â”‚                      â”‚ producer.py      â”‚                          â”‚
â”‚                      â”‚                  â”‚                          â”‚
â”‚                      â”‚ Python +         â”‚                          â”‚
â”‚                      â”‚ kafka-python     â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                               â”‚                                     â”‚
â”‚                               â”‚ Kafka Protocol                      â”‚
â”‚                               â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      APACHE KAFKA                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  ZOOKEEPER (Cluster coordination)                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  Port: 2181                                             â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  KAFKA BROKER                                           â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  Port: 9092                                             â”‚ â”‚  â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  Topic: crypto-prices                                   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Partition 0    â”‚  â”‚  Partition 1    â”‚              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  [msg][msg]...  â”‚  â”‚  [msg][msg]...  â”‚              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                               â”‚                                     â”‚
â”‚                               â”‚ Kafka Protocol                      â”‚
â”‚                               â–¼                                     â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚    CONSUMER      â”‚                          â”‚
â”‚                      â”‚ spark_streaming_ â”‚                          â”‚
â”‚                      â”‚ consumer.py      â”‚                          â”‚
â”‚                      â”‚                  â”‚                          â”‚
â”‚                      â”‚ PySpark +        â”‚                          â”‚
â”‚                      â”‚ Structured       â”‚                          â”‚
â”‚                      â”‚ Streaming        â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                               â”‚                                     â”‚
â”‚                               â”‚ Write to disk                       â”‚
â”‚                               â–¼                                     â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚     OUTPUT       â”‚                          â”‚
â”‚                      â”‚ streaming_       â”‚                          â”‚
â”‚                      â”‚ output_spark/    â”‚                          â”‚
â”‚                      â”‚   daily/         â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2. Files trong Speed Layer

```
week6_streaming/
â”œâ”€â”€ docker-compose.yml           # Config Kafka + Zookeeper
â”œâ”€â”€ websocket_producer.py        # Producer: Binance â†’ Kafka
â”œâ”€â”€ spark_streaming_consumer.py  # Consumer: Kafka â†’ Parquet
â””â”€â”€ README.md                    # HÆ°á»›ng dáº«n
```

---

## 3. Apache Kafka - Giáº£i thÃ­ch chi tiáº¿t

### 3.1. Kafka lÃ  gÃ¬?

```
Apache Kafka lÃ  má»™t DISTRIBUTED STREAMING PLATFORM:

1. PUBLISH-SUBSCRIBE messaging system
   â””â”€â”€ Producer gá»­i message
   â””â”€â”€ Consumer nháº­n message

2. DISTRIBUTED
   â””â”€â”€ Cháº¡y trÃªn nhiá»u server (cluster)
   â””â”€â”€ Fault tolerant (khÃ´ng máº¥t data)

3. HIGH-THROUGHPUT
   â””â”€â”€ Xá»­ lÃ½ hÃ ng triá»‡u messages/giÃ¢y
   â””â”€â”€ Low latency (< 10ms)

4. PERSISTENT
   â””â”€â”€ LÆ°u messages trÃªn disk
   â””â”€â”€ CÃ³ thá»ƒ replay messages
```

### 3.2. CÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        KAFKA CONCEPTS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. BROKER                                                          â”‚
â”‚     â””â”€â”€ Má»™t Kafka server                                           â”‚
â”‚     â””â”€â”€ LÆ°u trá»¯ vÃ  phÃ¢n phá»‘i messages                             â”‚
â”‚     â””â”€â”€ Trong project: 1 broker (localhost:9092)                  â”‚
â”‚                                                                     â”‚
â”‚  2. TOPIC                                                           â”‚
â”‚     â””â”€â”€ "Folder" chá»©a messages                                     â”‚
â”‚     â””â”€â”€ Producers gá»­i vÃ o topic                                    â”‚
â”‚     â””â”€â”€ Consumers Ä‘á»c tá»« topic                                     â”‚
â”‚     â””â”€â”€ Trong project: topic "crypto-prices"                       â”‚
â”‚                                                                     â”‚
â”‚  3. PARTITION                                                       â”‚
â”‚     â””â”€â”€ Chia nhá» topic                                             â”‚
â”‚     â””â”€â”€ Cho phÃ©p parallel processing                               â”‚
â”‚     â””â”€â”€ Trong project: 2 partitions                                â”‚
â”‚                                                                     â”‚
â”‚  4. PRODUCER                                                        â”‚
â”‚     â””â”€â”€ Gá»­i messages vÃ o topic                                     â”‚
â”‚     â””â”€â”€ Trong project: websocket_producer.py                       â”‚
â”‚                                                                     â”‚
â”‚  5. CONSUMER                                                        â”‚
â”‚     â””â”€â”€ Äá»c messages tá»« topic                                      â”‚
â”‚     â””â”€â”€ Trong project: spark_streaming_consumer.py                 â”‚
â”‚                                                                     â”‚
â”‚  6. ZOOKEEPER                                                       â”‚
â”‚     â””â”€â”€ Quáº£n lÃ½ Kafka cluster                                      â”‚
â”‚     â””â”€â”€ LÆ°u metadata                                               â”‚
â”‚     â””â”€â”€ Coordinator cho brokers                                    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3. Message flow trong Kafka

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MESSAGE FLOW                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Step 1: Producer gá»­i message                                       â”‚
â”‚                                                                     â”‚
â”‚  websocket_producer.py:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ {                                        â”‚                       â”‚
â”‚  â”‚   "symbol": "BTCUSDT",                   â”‚                       â”‚
â”‚  â”‚   "price": 92817.92,                     â”‚                       â”‚
â”‚  â”‚   "volume": 29318.80,                    â”‚                       â”‚
â”‚  â”‚   "timestamp": "2025-12-03T10:00:01"     â”‚                       â”‚
â”‚  â”‚ }                                        â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                    â”‚                                                â”‚
â”‚                    â”‚ producer.send("crypto-prices", message)        â”‚
â”‚                    â–¼                                                â”‚
â”‚                                                                     â”‚
â”‚  Step 2: Kafka lÆ°u message vÃ o partition                           â”‚
â”‚                                                                     â”‚
â”‚  Topic: crypto-prices                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  Partition 0: [msg1] [msg3] [msg5] [msg7] [msg9] ...       â”‚    â”‚
â”‚  â”‚               offset: 0     1      2      3      4          â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  Partition 1: [msg2] [msg4] [msg6] [msg8] [msg10] ...      â”‚    â”‚
â”‚  â”‚               offset: 0     1      2      3      4          â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                    â”‚                                                â”‚
â”‚                    â”‚ Kafka chá»n partition (round-robin hoáº·c key)   â”‚
â”‚                    â”‚                                                â”‚
â”‚                                                                     â”‚
â”‚  Step 3: Consumer Ä‘á»c messages                                      â”‚
â”‚                                                                     â”‚
â”‚  spark_streaming_consumer.py:                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ spark.readStream                        â”‚                       â”‚
â”‚  â”‚   .format("kafka")                      â”‚                       â”‚
â”‚  â”‚   .option("subscribe", "crypto-prices") â”‚                       â”‚
â”‚  â”‚   .load()                               â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                     â”‚
â”‚  â†’ Consumer Ä‘á»c tá»« cáº£ 2 partitions song song                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4. Táº¡i sao cáº§n Kafka?

```
KhÃ´ng cÃ³ Kafka (Direct connection):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  Producer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Consumer                  â”‚
â”‚                                                                     â”‚
â”‚  Váº¥n Ä‘á»:                                                           â”‚
â”‚  âŒ Náº¿u Consumer cháº­m â†’ Producer pháº£i Ä‘á»£i                          â”‚
â”‚  âŒ Náº¿u Consumer crash â†’ Máº¥t messages                              â”‚
â”‚  âŒ KhÃ´ng thá»ƒ cÃ³ nhiá»u Consumers                                   â”‚
â”‚  âŒ KhÃ´ng thá»ƒ replay messages                                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CÃ³ Kafka (Message broker):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  Producer â”€â”€â”€â”€â”€â–º KAFKA â”€â”€â”€â”€â”€â–º Consumer 1                           â”‚
â”‚                    â”‚                                                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â–º Consumer 2                           â”‚
â”‚                    â”‚                                                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â–º Consumer 3                           â”‚
â”‚                                                                     â”‚
â”‚  Lá»£i Ã­ch:                                                          â”‚
â”‚  âœ… DECOUPLING: Producer/Consumer Ä‘á»™c láº­p                          â”‚
â”‚  âœ… BUFFERING: Kafka giá»¯ messages náº¿u Consumer cháº­m                â”‚
â”‚  âœ… DURABILITY: Messages lÆ°u trÃªn disk, khÃ´ng máº¥t                  â”‚
â”‚  âœ… SCALABILITY: Nhiá»u Consumers Ä‘á»c cÃ¹ng topic                    â”‚
â”‚  âœ… REPLAY: CÃ³ thá»ƒ Ä‘á»c láº¡i messages cÅ©                             â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Docker vÃ  docker-compose.yml

### 4.1. Táº¡i sao dÃ¹ng Docker?

```
KhÃ´ng cÃ³ Docker:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  1. Táº£i Kafka binary tá»« Apache                                     â”‚
â”‚  2. CÃ i Ä‘áº·t Java JDK                                               â”‚
â”‚  3. Cáº¥u hÃ¬nh JAVA_HOME                                             â”‚
â”‚  4. Cáº¥u hÃ¬nh Kafka config files                                    â”‚
â”‚  5. Táº£i Zookeeper binary                                           â”‚
â”‚  6. Cáº¥u hÃ¬nh Zookeeper                                             â”‚
â”‚  7. Start Zookeeper                                                â”‚
â”‚  8. Start Kafka                                                    â”‚
â”‚  9. Debug náº¿u cÃ³ lá»—i...                                            â”‚
â”‚                                                                     â”‚
â”‚  â†’ Máº¥t 30 phÃºt - 1 tiáº¿ng, cÃ³ thá»ƒ gáº·p nhiá»u lá»—i                    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CÃ³ Docker:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  docker-compose up -d                                              â”‚
â”‚                                                                     â”‚
â”‚  â†’ 10 giÃ¢y, khÃ´ng cáº§n cÃ i Ä‘áº·t gÃ¬ thÃªm!                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2. Giáº£i thÃ­ch docker-compose.yml

```yaml
# docker-compose.yml - GIáº¢I THÃCH CHI TIáº¾T

version: '3.8'  # PhiÃªn báº£n docker-compose syntax

services:
  # ================================================================
  # SERVICE 1: ZOOKEEPER
  # ================================================================
  zookeeper:
    # Image: Confluent Zookeeper (production-grade)
    image: confluentinc/cp-zookeeper:7.5.0
    
    # TÃªn container (Ä‘á»ƒ dá»… identify)
    container_name: zookeeper
    
    # Biáº¿n mÃ´i trÆ°á»ng
    environment:
      # Port mÃ  clients connect
      ZOOKEEPER_CLIENT_PORT: 2181
      
      # Tick time (milliseconds) - heartbeat interval
      ZOOKEEPER_TICK_TIME: 2000
    
    # Port mapping: host:container
    # Cho phÃ©p access tá»« localhost:2181
    ports:
      - "2181:2181"
    
    # Network Ä‘á»ƒ cÃ¡c containers giao tiáº¿p
    networks:
      - crypto-network

  # ================================================================
  # SERVICE 2: KAFKA
  # ================================================================
  kafka:
    # Image: Confluent Kafka
    image: confluentinc/cp-kafka:7.5.0
    
    container_name: kafka
    
    # Kafka pháº£i Ä‘á»£i Zookeeper start trÆ°á»›c
    depends_on:
      - zookeeper
    
    # Port mapping
    ports:
      - "9092:9092"   # External clients (producer, consumer)
      - "9093:9093"   # Internal (giá»¯a cÃ¡c containers)
    
    environment:
      # ID cá»§a broker nÃ y
      KAFKA_BROKER_ID: 1
      
      # Äá»‹a chá»‰ Zookeeper
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      # Listeners: Kafka láº¯ng nghe á»Ÿ Ä‘Ã¢u
      # PLAINTEXT: KhÃ´ng encryption
      KAFKA_ADVERTISED_LISTENERS: >
        PLAINTEXT://localhost:9092,
        PLAINTEXT_INTERNAL://kafka:9093
      
      # Security protocol (khÃ´ng dÃ¹ng SSL/TLS)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >
        PLAINTEXT:PLAINTEXT,
        PLAINTEXT_INTERNAL:PLAINTEXT
      
      # Replication factor = 1 (chá»‰ cÃ³ 1 broker)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      
      # Tá»± Ä‘á»™ng táº¡o topic khi producer gá»­i message
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    
    networks:
      - crypto-network
    
    # Persist data
    volumes:
      - kafka-data:/var/lib/kafka/data

# ================================================================
# NETWORK
# ================================================================
networks:
  crypto-network:
    driver: bridge   # Default network driver

# ================================================================
# VOLUME
# ================================================================
volumes:
  kafka-data:        # Persistent storage cho Kafka data
```

### 4.3. CÃ¡c lá»‡nh Docker thÆ°á»ng dÃ¹ng

```bash
# Khá»Ÿi Ä‘á»™ng Kafka + Zookeeper (background)
docker-compose up -d

# Xem containers Ä‘ang cháº¡y
docker ps

# Xem logs cá»§a Kafka
docker logs kafka

# Xem logs cá»§a Zookeeper
docker logs zookeeper

# Dá»«ng táº¥t cáº£ containers
docker-compose down

# Dá»«ng vÃ  xÃ³a volumes (reset data)
docker-compose down -v

# List topics trong Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Táº¡o topic má»›i
docker exec kafka kafka-topics --create \
  --topic crypto-prices \
  --bootstrap-server localhost:9092 \
  --partitions 2 \
  --replication-factor 1

# Xem messages trong topic
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic crypto-prices \
  --from-beginning \
  --max-messages 5
```

---

## 5. Producer - websocket_producer.py

### 5.1. Tá»•ng quan

```python
"""
websocket_producer.py

Nhiá»‡m vá»¥:
1. Poll Binance API má»—i giÃ¢y
2. Gá»­i data vÃ o Kafka topic "crypto-prices"

Flow:
Binance API â†’ Python â†’ Kafka Producer â†’ Kafka Topic
"""
```

### 5.2. Kafka Producer Configuration

```python
def create_kafka_producer():
    """Táº¡o Kafka Producer vá»›i retry logic"""
    try:
        producer = KafkaProducer(
            # ============================================
            # BOOTSTRAP SERVERS
            # ============================================
            # Äá»‹a chá»‰ Kafka broker
            # CÃ³ thá»ƒ cÃ³ nhiá»u brokers: ['host1:9092', 'host2:9092']
            bootstrap_servers=['localhost:9092'],
            
            # ============================================
            # SERIALIZER
            # ============================================
            # Convert Python dict â†’ JSON bytes
            # Kafka chá»‰ nháº­n bytes, khÃ´ng nháº­n dict
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            
            # ============================================
            # RELIABILITY SETTINGS
            # ============================================
            # Sá»‘ láº§n retry náº¿u gá»­i tháº¥t báº¡i
            retries=3,
            
            # acks='all': Äá»£i táº¥t cáº£ replicas confirm
            # Cháº­m hÆ¡n nhÆ°ng Ä‘áº£m báº£o khÃ´ng máº¥t data
            # CÃ¡c options:
            #   acks=0: KhÃ´ng Ä‘á»£i confirm (nhanh, cÃ³ thá»ƒ máº¥t)
            #   acks=1: Äá»£i leader confirm (trung bÃ¬nh)
            #   acks='all': Äá»£i táº¥t cáº£ replicas (cháº­m, an toÃ n)
            acks='all',
            
            # ============================================
            # PERFORMANCE SETTINGS
            # ============================================
            # NÃ©n data báº±ng gzip (giáº£m bandwidth)
            compression_type='gzip',
            
            # Chá»‰ 1 request in-flight táº¡i 1 thá»i Ä‘iá»ƒm
            # Äáº£m báº£o thá»© tá»± messages
            max_in_flight_requests_per_connection=1
        )
        logger.info(f"âœ“ Kafka Producer connected to {KAFKA_BOOTSTRAP_SERVERS}")
        return producer
    except Exception as e:
        logger.error(f"âœ— Failed to create Kafka Producer: {e}")
        raise
```

### 5.3. Fetch data tá»« Binance

```python
def fetch_ticker_data(symbol):
    """
    Láº¥y dá»¯ liá»‡u ticker 24hr tá»« Binance API
    
    API Endpoint: GET /api/v3/ticker/24hr
    
    Returns 24-hour statistics cho symbol
    """
    try:
        # Binance ticker API
        url = f"https://api.binance.com/api/v3/ticker/24hr?symbol={symbol.upper()}"
        
        # HTTP GET vá»›i timeout 5 giÃ¢y
        response = requests.get(url, timeout=5)
        response.raise_for_status()  # Raise exception náº¿u HTTP error
        
        data = response.json()
        
        # Transform data
        return {
            'symbol': data['symbol'],           # "BTCUSDT"
            'event_time': int(data['closeTime']),  # Timestamp (ms)
            'price': float(data['lastPrice']),  # GiÃ¡ hiá»‡n táº¡i
            'open': float(data['openPrice']),   # GiÃ¡ má»Ÿ cá»­a 24h
            'high': float(data['highPrice']),   # GiÃ¡ cao nháº¥t 24h
            'low': float(data['lowPrice']),     # GiÃ¡ tháº¥p nháº¥t 24h
            'volume': float(data['volume']),    # Volume 24h (BTC)
            'quote_volume': float(data['quoteVolume']),  # Volume 24h (USDT)
            'number_trades': int(data['count']),  # Sá»‘ giao dá»‹ch 24h
            'price_change': float(data['priceChange']),  # Thay Ä‘á»•i giÃ¡
            'price_change_percent': float(data['priceChangePercent']),  # % thay Ä‘á»•i
            'timestamp': datetime.now().isoformat()  # Timestamp local
        }
    except Exception as e:
        logger.error(f"Error fetching {symbol}: {e}")
        return None
```

### 5.4. Main loop - Continuous streaming

```python
def main():
    """Khá»Ÿi Ä‘á»™ng continuous streaming vÃ o Kafka"""
    
    # Táº¡o Kafka Producer
    producer = create_kafka_producer()
    
    symbols = ['BTCUSDT', 'ETHUSDT']
    
    try:
        # ============================================
        # INFINITE LOOP - Cháº¡y liÃªn tá»¥c
        # ============================================
        while True:
            for symbol in symbols:
                # Fetch data tá»« Binance
                data = fetch_ticker_data(symbol)
                
                if data:
                    # ============================================
                    # Gá»¬I VÃ€O KAFKA
                    # ============================================
                    # producer.send() tráº£ vá» Future
                    # future.get() Ä‘á»£i cho Ä‘áº¿n khi gá»­i xong
                    future = producer.send(KAFKA_TOPIC, value=data)
                    future.get(timeout=10)  # Block until sent
                    
                    # Log má»—i 10 messages
                    if message_count[symbol] % 10 == 0:
                        logger.info(f"ğŸ“Š {symbol}: ${data['price']:,.2f}")
            
            # ============================================
            # SLEEP 1 SECOND
            # ============================================
            # Polling rate: 1 request/second/symbol
            # = 2 requests/second total (BTC + ETH)
            time.sleep(1)
            
    except KeyboardInterrupt:
        # User nháº¥n Ctrl+C
        logger.info("\nâ¹ Stopping producer...")
        producer.flush()   # Gá»­i háº¿t messages cÃ²n trong buffer
        producer.close()   # ÄÃ³ng connection
```

### 5.5. Message format

```json
{
    "symbol": "BTCUSDT",
    "event_time": 1764730800011,
    "price": 92817.92,
    "open": 86554.46,
    "high": 93051.64,
    "low": 86214.99,
    "volume": 29318.80585,
    "quote_volume": 2635333520.175692,
    "number_trades": 6468949,
    "price_change": 6263.46,
    "price_change_percent": 7.236,
    "timestamp": "2025-12-03T10:00:01.226298"
}
```

---

## 6. Consumer - spark_streaming_consumer.py

### 6.1. Tá»•ng quan

```python
"""
spark_streaming_consumer.py

ÄÃ¢y lÃ  STRUCTURED STREAMING tháº­t sá»±:
- Äá»c continuous stream tá»« Kafka
- Micro-batch processing (trigger 10s)
- Watermarking (xá»­ lÃ½ late data)
- Window aggregation (1 day, 1 hour)
- Checkpoint (fault tolerance)
"""
```

### 6.2. Spark Session Configuration

```python
spark = SparkSession.builder \
    # TÃªn application (hiá»ƒn thá»‹ trong Spark UI)
    .appName("CryptoPriceStructuredStreaming") \
    
    # ThÃªm Kafka connector package
    # Spark khÃ´ng cÃ³ sáºµn Kafka support, cáº§n thÃªm dependency
    .config("spark.jars.packages", 
            "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3") \
    
    # NÆ¡i lÆ°u checkpoints (fault tolerance)
    .config("spark.sql.streaming.checkpointLocation", "checkpoint_spark") \
    
    # Báº­t Adaptive Query Execution
    .config("spark.sql.adaptive.enabled", "true") \
    
    # Memory cho driver
    .config("spark.driver.memory", "4g") \
    .getOrCreate()
```

### 6.3. Schema Definition

```python
# Schema cho JSON message tá»« Kafka
# Pháº£i match vá»›i format mÃ  Producer gá»­i
message_schema = StructType([
    StructField("symbol", StringType(), True),        # "BTCUSDT"
    StructField("event_time", LongType(), True),      # Timestamp (ms)
    StructField("price", DoubleType(), True),         # 92817.92
    StructField("open", DoubleType(), True),          # 86554.46
    StructField("high", DoubleType(), True),          # 93051.64
    StructField("low", DoubleType(), True),           # 86214.99
    StructField("volume", DoubleType(), True),        # 29318.80
    StructField("quote_volume", DoubleType(), True),  # 2635333520.17
    StructField("number_trades", IntegerType(), True),# 6468949
    StructField("price_change", DoubleType(), True),  # 6263.46
    StructField("price_change_percent", DoubleType(), True),  # 7.236
    StructField("timestamp", StringType(), True)      # ISO format
])
```

### 6.4. Read Stream tá»« Kafka

```python
# ============================================
# STEP 1: Äá»ŒC Tá»ª KAFKA
# ============================================
kafkaDF = spark.readStream \
    # Format: Kafka source
    .format("kafka") \
    
    # Äá»‹a chá»‰ Kafka broker
    .option("kafka.bootstrap.servers", "localhost:9092") \
    
    # Subscribe topic "crypto-prices"
    .option("subscribe", "crypto-prices") \
    
    # Báº¯t Ä‘áº§u tá»« Ä‘Ã¢u:
    # - "earliest": Äá»c tá»« Ä‘áº§u
    # - "latest": Chá»‰ Ä‘á»c messages má»›i
    .option("startingOffsets", "earliest") \
    
    # KhÃ´ng fail náº¿u máº¥t data (cho demo)
    .option("failOnDataLoss", "false") \
    .load()

# Kafka DataFrame cÃ³ cÃ¡c cá»™t:
# key, value, topic, partition, offset, timestamp, timestampType
# - key: CÃ³ thá»ƒ null
# - value: JSON message (bytes)
# - topic: "crypto-prices"
# - partition: 0 hoáº·c 1
# - offset: Vá»‹ trÃ­ trong partition
# - timestamp: Kafka timestamp
```

### 6.5. Parse JSON

```python
# ============================================
# STEP 2: PARSE JSON
# ============================================
parsedDF = kafkaDF.select(
    # Parse JSON tá»« cá»™t "value"
    # value lÃ  bytes, cast sang string trÆ°á»›c
    from_json(
        col("value").cast("string"),  # bytes â†’ string
        message_schema                 # Schema Ä‘Ã£ Ä‘á»‹nh nghÄ©a
    ).alias("data"),
    
    # Giá»¯ láº¡i Kafka timestamp
    col("timestamp").alias("kafka_timestamp")
)

# Expand nested columns
# data.symbol, data.price, etc â†’ symbol, price, etc
.select("data.*", "kafka_timestamp")
```

### 6.6. Data Transformation

```python
# ============================================
# STEP 3: TRANSFORM DATA
# ============================================
streamDF = parsedDF \
    # Convert event_time (milliseconds) â†’ timestamp
    .withColumn(
        "event_timestamp",
        (col("event_time") / 1000).cast("timestamp")
    ) \
    
    # Extract date
    .withColumn("date", to_date(col("event_timestamp"))) \
    
    # Extract hour
    .withColumn("hour", hour(col("event_timestamp")))

# VÃ­ dá»¥:
# event_time = 1764730800011 (ms)
# event_timestamp = 2025-12-03 10:00:00
# date = 2025-12-03
# hour = 10
```

---

## 7. Watermark vÃ  Window

### 7.1. Watermark lÃ  gÃ¬?

```
WATERMARK: Xá»­ lÃ½ late data (dá»¯ liá»‡u Ä‘áº¿n muá»™n)

Váº¥n Ä‘á»:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  10:00:00 - Message 1 arrive (event_time: 10:00:00) âœ“              â”‚
â”‚  10:00:01 - Message 2 arrive (event_time: 10:00:01) âœ“              â”‚
â”‚  10:00:02 - Message 3 arrive (event_time: 09:59:30) â† LATE!        â”‚
â”‚                                                                     â”‚
â”‚  Message 3 cÃ³ event_time trong quÃ¡ khá»© (09:59:30)                  â”‚
â”‚  Äiá»u nÃ y xáº£y ra do network delay, retry, v.v.                     â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Giáº£i phÃ¡p: Watermark

Watermark = Current max event_time - Threshold

VÃ­ dá»¥ vá»›i threshold 1 hour:
  Current max event_time = 10:00:00
  Watermark = 10:00:00 - 1 hour = 09:00:00
  
  Message vá»›i event_time > 09:00:00 â†’ ÄÆ°á»£c xá»­ lÃ½ âœ“
  Message vá»›i event_time â‰¤ 09:00:00 â†’ Bá»‹ drop âœ—
```

### 7.2. Code Watermark

```python
# ============================================
# STEP 4: WATERMARKING
# ============================================
watermarkedDF = streamDF.withWatermark("event_timestamp", "1 hour")

# Giáº£i thÃ­ch:
# - "event_timestamp": Cá»™t chá»©a event time
# - "1 hour": Threshold - cháº¥p nháº­n late data Ä‘áº¿n 1 giá»

# VÃ­ dá»¥:
# Current event_timestamp = 10:30:00
# Watermark = 09:30:00
# 
# Message vá»›i event_timestamp = 10:00:00 â†’ OK (> 09:30:00)
# Message vá»›i event_timestamp = 09:00:00 â†’ DROP (â‰¤ 09:30:00)
```

### 7.3. Window Aggregation

```python
# ============================================
# STEP 5: WINDOW AGGREGATION - DAILY
# ============================================
dailyDF = watermarkedDF \
    .groupBy(
        # Window: NhÃ³m theo khoáº£ng thá»i gian
        # window(timestamp_column, window_duration)
        window(col("event_timestamp"), "1 day"),
        
        # ThÃªm groupBy symbol
        col("symbol")
    ) \
    .agg(
        # OHLC (Open, High, Low, Close)
        first("open").alias("daily_open"),
        max("high").alias("daily_high"),
        min("low").alias("daily_low"),
        last("price").alias("daily_close"),
        
        # Volume
        sum("volume").alias("daily_volume"),
        sum("quote_volume").alias("daily_quote_volume"),
        
        # Trades
        sum("number_trades").alias("total_trades"),
        
        # Statistics
        count("*").alias("tick_count"),      # Sá»‘ messages
        avg("price").alias("avg_price")      # GiÃ¡ trung bÃ¬nh
    )

# Window táº¡o ra cá»™t "window" cÃ³ 2 fields:
# - window.start: Báº¯t Ä‘áº§u window
# - window.end: Káº¿t thÃºc window

# VÃ­ dá»¥:
# window.start = 2025-12-03 00:00:00
# window.end = 2025-12-04 00:00:00
```

### 7.4. Minh há»a Window

```
Window 1 day vá»›i data stream:

Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
  00:00        06:00        12:00        18:00        00:00
  â”‚             â”‚             â”‚             â”‚             â”‚
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Window Day 1 (Dec 3) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚             â”‚             â”‚             â”‚             â”‚
  â”‚ msg1  msg2  â”‚   msg3      â”‚  msg4  msg5  â”‚    msg6    â”‚
  â”‚             â”‚             â”‚             â”‚             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Táº¥t cáº£ messages trong Day 1 Ä‘Æ°á»£c aggregate:
- daily_open = first(open) = msg1.open
- daily_high = max(high) = max(msg1.high, msg2.high, ..., msg6.high)
- daily_low = min(low)
- daily_close = last(price) = msg6.price
- daily_volume = sum(volume)
```

---

## 8. Output vÃ  Checkpoint

### 8.1. Write Streams

```python
# ============================================
# QUERY 1: Daily data â†’ Parquet
# ============================================
daily_query = dailyDF.writeStream \
    # Output mode:
    # - "append": Chá»‰ ghi records má»›i
    # - "complete": Ghi láº¡i toÃ n bá»™ result
    # - "update": Ghi records thay Ä‘á»•i
    .outputMode("append") \
    
    # Format output
    .format("parquet") \
    
    # ÄÆ°á»ng dáº«n output
    .option("path", "streaming_output_spark/daily") \
    
    # Checkpoint location (fault tolerance)
    .option("checkpointLocation", "checkpoint_spark/daily") \
    
    # Partition theo symbol
    .partitionBy("symbol") \
    
    # Trigger: Cháº¡y má»—i 10 giÃ¢y
    # CÃ¡c options:
    # - processingTime="10 seconds": Cháº¡y má»—i 10s
    # - continuous="1 second": True streaming (experimental)
    # - once=True: Cháº¡y 1 láº§n rá»“i stop
    .trigger(processingTime="10 seconds") \
    .start()

# ============================================
# QUERY 2: Raw data â†’ Console (monitoring)
# ============================================
console_query = streamDF \
    .select("symbol", "price", "volume", "price_change_percent", "event_timestamp") \
    .writeStream \
    .outputMode("append") \
    .format("console")          # In ra console
    .option("truncate", "false")
    .option("numRows", "10")    # Max 10 rows
    .trigger(processingTime="30 seconds")
    .start()

# ============================================
# QUERY 4: Daily stats â†’ Memory (for queries)
# ============================================
stats_query = dailyDF.writeStream \
    .outputMode("complete")     # Ghi toÃ n bá»™
    .format("memory")           # LÆ°u trong memory
    .queryName("crypto_daily_stats")  # TÃªn table
    .trigger(processingTime="10 seconds")
    .start()

# CÃ³ thá»ƒ query:
# spark.sql("SELECT * FROM crypto_daily_stats").show()
```

### 8.2. Checkpoint - Fault Tolerance

```
Checkpoint lÃ  gÃ¬?
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  Checkpoint lÆ°u tráº¡ng thÃ¡i cá»§a streaming query:                    â”‚
â”‚                                                                     â”‚
â”‚  1. OFFSET: ÄÃ£ Ä‘á»c Ä‘áº¿n offset nÃ o trong Kafka                      â”‚
â”‚  2. STATE: Tráº¡ng thÃ¡i aggregation (window states)                  â”‚
â”‚  3. METADATA: Query information                                     â”‚
â”‚                                                                     â”‚
â”‚  Táº¡i sao cáº§n?                                                       â”‚
â”‚  - Náº¿u Spark crash, restart sáº½ Ä‘á»c checkpoint                      â”‚
â”‚  - Tiáº¿p tá»¥c tá»« chá»— dá»«ng, khÃ´ng xá»­ lÃ½ láº¡i tá»« Ä‘áº§u                   â”‚
â”‚  - KhÃ´ng máº¥t data, khÃ´ng duplicate                                 â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cáº¥u trÃºc checkpoint folder:
checkpoint_spark/
â””â”€â”€ daily/
    â”œâ”€â”€ offsets/           # Kafka offsets Ä‘Ã£ Ä‘á»c
    â”‚   â”œâ”€â”€ 0
    â”‚   â”œâ”€â”€ 1
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ commits/           # Batches Ä‘Ã£ commit
    â”œâ”€â”€ state/             # Aggregation state
    â””â”€â”€ metadata           # Query metadata
```

### 8.3. Output Structure

```
streaming_output_spark/
â””â”€â”€ daily/
    â”œâ”€â”€ symbol=BTCUSDT/
    â”‚   â”œâ”€â”€ part-00000-xxx.snappy.parquet
    â”‚   â””â”€â”€ ...
    â””â”€â”€ symbol=ETHUSDT/
        â””â”€â”€ ...

LÆ°u Ã½:
- Append mode: Má»—i trigger táº¡o file má»›i
- CÃ³ thá»ƒ cÃ³ nhiá»u small files
- Cáº§n compact Ä‘á»‹nh ká»³ trong production
```

---

## 9. CÃ¢u há»i thÆ°á»ng gáº·p

### Q1: Táº¡i sao dÃ¹ng Kafka thay vÃ¬ gá»­i tháº³ng vÃ o Spark?

```
A: Kafka mang láº¡i nhiá»u lá»£i Ã­ch:

1. DECOUPLING:
   - Producer vÃ  Consumer Ä‘á»™c láº­p
   - CÃ³ thá»ƒ restart má»™t bÃªn mÃ  khÃ´ng áº£nh hÆ°á»Ÿng bÃªn kia

2. BUFFERING:
   - Náº¿u Spark cháº­m, Kafka giá»¯ messages
   - KhÃ´ng máº¥t data

3. REPLAY:
   - CÃ³ thá»ƒ Ä‘á»c láº¡i messages tá»« Ä‘áº§u
   - Debug dá»… dÃ ng

4. MULTI-CONSUMER:
   - Nhiá»u consumers Ä‘á»c cÃ¹ng topic
   - CÃ³ thá»ƒ thÃªm consumer analytics, monitoring, etc

5. DURABILITY:
   - Messages lÆ°u trÃªn disk
   - KhÃ´ng máº¥t khi crash
```

### Q2: Táº¡i sao dÃ¹ng Structured Streaming thay vÃ¬ DStreams?

```
A: Structured Streaming lÃ  API má»›i vÃ  tá»‘t hÆ¡n:

DStreams (cÅ©):
â”œâ”€â”€ RDD-based
â”œâ”€â”€ KhÃ³ debug
â”œâ”€â”€ KhÃ´ng cÃ³ exactly-once semantics
â””â”€â”€ Deprecated

Structured Streaming (má»›i):
â”œâ”€â”€ DataFrame/SQL API
â”œâ”€â”€ Dá»… sá»­ dá»¥ng hÆ¡n
â”œâ”€â”€ Exactly-once semantics
â”œâ”€â”€ TÃ­ch há»£p vá»›i Spark SQL
â”œâ”€â”€ Watermark, Window built-in
â””â”€â”€ Production-ready
```

### Q3: Watermark 1 hour cÃ³ quÃ¡ dÃ i khÃ´ng?

```
A: TÃ¹y use case:

1 hour watermark nghÄ©a lÃ :
- Cháº¥p nháº­n late data Ä‘áº¿n 1 giá»
- State giá»¯ trong memory 1 giá»
- Tradeoff: Memory vs Tolerance

Trong project:
- 1 hour lÃ  conservative
- Binance API cÃ³ thá»ƒ delay vÃ i giÃ¢y â†’ 1 hour quÃ¡ dÆ°
- CÃ³ thá»ƒ giáº£m xuá»‘ng 5-10 phÃºt cho production

CÃ¡c giÃ¡ trá»‹ phá»• biáº¿n:
- IoT sensors: 1-5 phÃºt
- Mobile app events: 5-15 phÃºt
- Batch-like streaming: 1-24 giá»
```

### Q4: Trigger 10 seconds cÃ³ Ã½ nghÄ©a gÃ¬?

```
A: Trigger xÃ¡c Ä‘á»‹nh táº§n suáº¥t processing:

trigger(processingTime="10 seconds"):
â”œâ”€â”€ Spark Ä‘á»£i 10 giÃ¢y
â”œâ”€â”€ Thu tháº­p messages trong 10s Ä‘Ã³
â”œâ”€â”€ Xá»­ lÃ½ micro-batch
â”œâ”€â”€ Output káº¿t quáº£
â””â”€â”€ Láº·p láº¡i

Micro-batch vs True streaming:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  Micro-batch (10s trigger):                                        â”‚
â”‚  â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–º                         â”‚
â”‚      â”‚ batch1 â”‚ batch2 â”‚ batch3 â”‚                                  â”‚
â”‚     10s      20s      30s      40s                                 â”‚
â”‚                                                                     â”‚
â”‚  True streaming (continuous):                                       â”‚
â”‚  â”€â”€â”€â”€â”€msgâ”€msgâ”€msgâ”€msgâ”€msgâ”€msgâ”€msgâ”€â”€â”€â”€â”€â–º                            â”‚
â”‚  Xá»­ lÃ½ ngay tá»«ng message                                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

10 seconds lÃ  good default:
- KhÃ´ng quÃ¡ cháº­m (cÃ³ káº¿t quáº£ má»—i 10s)
- KhÃ´ng quÃ¡ nhanh (overhead tháº¥p)
- PhÃ¹ há»£p cho demo
```

### Q5: Táº¡i sao cáº§n cáº£ Parquet output vÃ  Memory table?

```
A: Hai má»¥c Ä‘Ã­ch khÃ¡c nhau:

Parquet output:
â”œâ”€â”€ Persistent storage
â”œâ”€â”€ CÃ³ thá»ƒ Ä‘á»c láº¡i sau khi Spark stop
â”œâ”€â”€ DÃ¹ng cho Serving Layer merge

Memory table:
â”œâ”€â”€ Real-time monitoring
â”œâ”€â”€ Query ngay láº­p tá»©c
â”œâ”€â”€ Máº¥t khi Spark stop

Trong project:
- Parquet: Serving Layer Ä‘á»c Ä‘á»ƒ merge vá»›i Batch Layer
- Memory: Demo realtime, query trá»±c tiáº¿p
```

---

## ğŸ“š TÃ i liá»‡u tiáº¿p theo

Sau khi hiá»ƒu Speed Layer, tiáº¿p tá»¥c vá»›i:

**WEEK6_04_SERVING_LAYER.md** - Giáº£i thÃ­ch merge + forecast

---

*Táº¡o bá»Ÿi: Big Data Project - Week 6 Documentation*
*Cáº­p nháº­t: 03/12/2025*
